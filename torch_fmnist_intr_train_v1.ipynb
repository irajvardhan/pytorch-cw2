{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pytorch Explanation based Model for Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ref: tensorflow version from http://localhost:8888/notebooks/xai-adv/train_exp_based_model_v1.4_FMNIST_defender.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### difference from FMNIST training is the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data as D\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from keras import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, features, num_classes, init_weights=True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4*4*50, 500),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(500, num_classes)\n",
    "        )\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        # x are the logits values\n",
    "        return x \n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            output = F.log_softmax(output, dim=1)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\"\"\"\n",
    "\n",
    "def make_layers(cfg, in_channels, kernel_size, stride, padding, batch_norm=False):\n",
    "    layers = []\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=kernel_size, padding=padding)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Refer VGG19_bn configurationh here: \n",
    "https://github.com/pytorch/vision/blob/76702a03d6cc2e4f431bfd1914d5e301c07bd489/torchvision/models/vgg.py#L63\n",
    "\"\"\"\n",
    "cfgs = {\n",
    "    #'E': [64, 64, 'M',128, 128, 'M',256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M',512, 512, 512, 512, 'M'],\n",
    "    'E': [20, 'M', 50, 'M']\n",
    "}\n",
    "\n",
    "model_layers = make_layers(cfgs['E'],in_channels=1, kernel_size=5, stride=1, padding=0, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomDS(D.Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, train=True):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            data_path = os.path.join(path,'x_train.npy')\n",
    "            targets_path = os.path.join(path,'y_train.npy')\n",
    "        else:\n",
    "            data_path = os.path.join(path,'x_test.npy')\n",
    "            targets_path = os.path.join(path,'y_test.npy')\n",
    "        self.path = data_path\n",
    "        self.data = np.load(data_path)\n",
    "        self.targets = np.load(targets_path)\n",
    "        #self.transform = transforms.ToTensor()\n",
    "        self.transform = transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "        self.len = np.shape(self.data)[0]\n",
    "        \n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        data = self.data[index]\n",
    "        image = Image.fromarray(data)\n",
    "        \n",
    "        target = int(self.targets[index])\n",
    "        \n",
    "        #data = (data * 255).astype(np.uint8)\n",
    "        #data = data.reshape(28,28)\n",
    "        #image = Image.fromarray((data * 255).astype(np.uint8))\n",
    "        #image = Image.fromarray(data.astype(np.uint8))\n",
    "        \n",
    "        return self.transform(image), target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig 9 : (5988, 28, 28, 1)\n",
      "adv 9 : (3126, 28, 28, 1)\n",
      "\n",
      "\n",
      "total shape (11976, 28, 28)\n",
      "x_train shape : (7664, 28, 28)\n",
      "y_train shape : (7664,)\n",
      "x_test shape : (2396, 28, 28)\n",
      "y_test shape : (2396,)\n",
      "x_valid shape : (1916, 28, 28)\n",
      "y_valid shape : (1916,)\n"
     ]
    }
   ],
   "source": [
    "IS_DATA_READY = False\n",
    "\n",
    "if not IS_DATA_READY:\n",
    "    \n",
    "    class_ind = 9\n",
    "    directory = 'data/defender/fmnist/exp_model/for_target/' + str(class_ind)\n",
    "    clean_intr_train_dir = 'data/defender/fmnist/intr_of_clean_train_bytarget/' + str(class_ind)\n",
    "\n",
    "    ox = np.load(clean_intr_train_dir + '/cleaned_intr_of_x_train.npy')\n",
    "    ax = np.load(directory + '/intr_of_adv_with_target_'  + str(class_ind) + '.npy')\n",
    "\n",
    "    print('orig {} : {}'.format(class_ind, ox.shape))\n",
    "    print('adv {} : {}'.format(class_ind, ax.shape))\n",
    "    print('\\n')\n",
    "    ax = np.vstack((ax,ax))\n",
    "    ax = np.vstack((ax,ax))\n",
    "    ax = np.vstack((ax,ax))\n",
    "    ax = np.vstack((ax,ax))\n",
    "\n",
    "    ax = ax[:ox.shape[0]]\n",
    "\n",
    "    # shuffle ax\n",
    "    indices = np.arange(ax.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    ax = ax[indices]\n",
    "\n",
    "    class_0 = ox\n",
    "    class_1 = ax\n",
    "\n",
    "    total_x = np.concatenate((class_0, class_1))\n",
    "    total_x = total_x.reshape(-1,28,28)\n",
    "\n",
    "    print('total shape {}'.format(total_x.shape))\n",
    "\n",
    "    y_0 = np.zeros((len(class_0)))\n",
    "    y_1 = np.ones((len(class_1)))\n",
    "\n",
    "    total_y = np.concatenate((y_0, y_1))\n",
    "    \n",
    "    #train, test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(total_x,total_y,test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "    #train, valid split from the remaining train set (after test set has been taken out)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train,test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "    \n",
    "    print('x_train shape : {}'.format(x_train.shape))\n",
    "    print('y_train shape : {}'.format(y_train.shape))\n",
    "    print('x_test shape : {}'.format(x_test.shape))\n",
    "    print('y_test shape : {}'.format(y_test.shape))\n",
    "    print('x_valid shape : {}'.format(x_valid.shape))\n",
    "    print('y_valid shape : {}'.format(y_valid.shape))\n",
    "    \n",
    "    directory = 'data/defender/fmnist/exp_model_data/for_target/' + str(class_ind)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    np.save(directory + '/x_train.npy', x_train)\n",
    "    np.save(directory + '/y_train.npy', y_train)\n",
    "    np.save(directory + '/x_test.npy', x_test)\n",
    "    np.save(directory + '/y_test.npy', y_test)\n",
    "    np.save(directory + '/x_valid.npy', x_valid)\n",
    "    np.save(directory + '/y_valid.npy', y_valid)\n",
    "\n",
    "else:\n",
    "    class_ind = 6\n",
    "    directory = 'data/defender/fmnist/exp_model_data/for_target/' + str(class_ind)\n",
    "    \n",
    "    x_train = np.load(directory + '/x_train.npy')\n",
    "    y_train = np.load(directory + '/y_train.npy')\n",
    "    x_test = np.load(directory + '/x_test.npy')\n",
    "    y_test = np.load(directory + '/y_test.npy')\n",
    "    x_valid = np.load(directory + '/x_valid.npy')\n",
    "    y_valid = np.load(directory + '/x_valid.npy')\n",
    "    \n",
    "    print('x_train shape : {}'.format(x_train.shape))\n",
    "    print('y_train shape : {}'.format(y_train.shape))\n",
    "    print('x_test shape : {}'.format(x_test.shape))\n",
    "    print('y_test shape : {}'.format(y_test.shape))\n",
    "    print('x_valid shape : {}'.format(x_valid.shape))\n",
    "    print('y_valid shape : {}'.format(y_valid.shape))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(x_train[0]))\n",
    "print(np.max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7664\n",
      "2396\n"
     ]
    }
   ],
   "source": [
    "# Simple dataset. Only save path to image and load it and transform to tensor when call __getitem__.\n",
    "filepath = directory\n",
    "train_set = CustomDS(filepath, train=True)\n",
    "test_set = CustomDS(filepath, train=False)\n",
    "\n",
    "# total images in set\n",
    "print(train_set.len)\n",
    "print(test_set.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main method\n",
    "## Training settings\n",
    "# input batch size for training (default: 64)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# input batch size for testing (default: 1000)\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "# number of epochs to train\n",
    "EPOCHS = 50\n",
    "\n",
    "#learning rate (default: 0.01)\n",
    "LR = 0.01\n",
    "\n",
    "#SGD momentum (default: 0.5)\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "# how many batches to wait before logging training status\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "SAVE_MODEL = True\n",
    "SEED = 1\n",
    "NO_CUDA = False\n",
    "USE_CUDA = not NO_CUDA and torch.cuda.is_available()\n",
    "\n",
    "NUM_CLASSES=2 # we are training a binary model (0 for normal or 1 for abnormal)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net(model_layers, num_classes=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=500, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/7664 (0%)]\tLoss: 0.693162\n",
      "Train Epoch: 1 [640/7664 (8%)]\tLoss: 0.692534\n",
      "Train Epoch: 1 [1280/7664 (17%)]\tLoss: 0.693453\n",
      "Train Epoch: 1 [1920/7664 (25%)]\tLoss: 0.692236\n",
      "Train Epoch: 1 [2560/7664 (33%)]\tLoss: 0.693346\n",
      "Train Epoch: 1 [3200/7664 (42%)]\tLoss: 0.692453\n",
      "Train Epoch: 1 [3840/7664 (50%)]\tLoss: 0.691006\n",
      "Train Epoch: 1 [4480/7664 (58%)]\tLoss: 0.691412\n",
      "Train Epoch: 1 [5120/7664 (67%)]\tLoss: 0.692710\n",
      "Train Epoch: 1 [5760/7664 (75%)]\tLoss: 0.691222\n",
      "Train Epoch: 1 [6400/7664 (83%)]\tLoss: 0.691988\n",
      "Train Epoch: 1 [7040/7664 (92%)]\tLoss: 0.688893\n",
      "\n",
      "Test set: Average loss: 0.6915, Accuracy: 1167/2396 (49%)\n",
      "\n",
      "Train Epoch: 2 [0/7664 (0%)]\tLoss: 0.692775\n",
      "Train Epoch: 2 [640/7664 (8%)]\tLoss: 0.689672\n",
      "Train Epoch: 2 [1280/7664 (17%)]\tLoss: 0.694326\n",
      "Train Epoch: 2 [1920/7664 (25%)]\tLoss: 0.691359\n",
      "Train Epoch: 2 [2560/7664 (33%)]\tLoss: 0.690614\n",
      "Train Epoch: 2 [3200/7664 (42%)]\tLoss: 0.690314\n",
      "Train Epoch: 2 [3840/7664 (50%)]\tLoss: 0.687412\n",
      "Train Epoch: 2 [4480/7664 (58%)]\tLoss: 0.687886\n",
      "Train Epoch: 2 [5120/7664 (67%)]\tLoss: 0.691147\n",
      "Train Epoch: 2 [5760/7664 (75%)]\tLoss: 0.688197\n",
      "Train Epoch: 2 [6400/7664 (83%)]\tLoss: 0.689837\n",
      "Train Epoch: 2 [7040/7664 (92%)]\tLoss: 0.685862\n",
      "\n",
      "Test set: Average loss: 0.6887, Accuracy: 1303/2396 (54%)\n",
      "\n",
      "Train Epoch: 3 [0/7664 (0%)]\tLoss: 0.689854\n",
      "Train Epoch: 3 [640/7664 (8%)]\tLoss: 0.687028\n",
      "Train Epoch: 3 [1280/7664 (17%)]\tLoss: 0.692802\n",
      "Train Epoch: 3 [1920/7664 (25%)]\tLoss: 0.687530\n",
      "Train Epoch: 3 [2560/7664 (33%)]\tLoss: 0.687300\n",
      "Train Epoch: 3 [3200/7664 (42%)]\tLoss: 0.687272\n",
      "Train Epoch: 3 [3840/7664 (50%)]\tLoss: 0.683318\n",
      "Train Epoch: 3 [4480/7664 (58%)]\tLoss: 0.681272\n",
      "Train Epoch: 3 [5120/7664 (67%)]\tLoss: 0.687680\n",
      "Train Epoch: 3 [5760/7664 (75%)]\tLoss: 0.682668\n",
      "Train Epoch: 3 [6400/7664 (83%)]\tLoss: 0.685299\n",
      "Train Epoch: 3 [7040/7664 (92%)]\tLoss: 0.680968\n",
      "\n",
      "Test set: Average loss: 0.6827, Accuracy: 1678/2396 (70%)\n",
      "\n",
      "Train Epoch: 4 [0/7664 (0%)]\tLoss: 0.682733\n",
      "Train Epoch: 4 [640/7664 (8%)]\tLoss: 0.681965\n",
      "Train Epoch: 4 [1280/7664 (17%)]\tLoss: 0.688037\n",
      "Train Epoch: 4 [1920/7664 (25%)]\tLoss: 0.677629\n",
      "Train Epoch: 4 [2560/7664 (33%)]\tLoss: 0.680123\n",
      "Train Epoch: 4 [3200/7664 (42%)]\tLoss: 0.680434\n",
      "Train Epoch: 4 [3840/7664 (50%)]\tLoss: 0.674353\n",
      "Train Epoch: 4 [4480/7664 (58%)]\tLoss: 0.664296\n",
      "Train Epoch: 4 [5120/7664 (67%)]\tLoss: 0.678374\n",
      "Train Epoch: 4 [5760/7664 (75%)]\tLoss: 0.667806\n",
      "Train Epoch: 4 [6400/7664 (83%)]\tLoss: 0.672504\n",
      "Train Epoch: 4 [7040/7664 (92%)]\tLoss: 0.667453\n",
      "\n",
      "Test set: Average loss: 0.6649, Accuracy: 1782/2396 (74%)\n",
      "\n",
      "Train Epoch: 5 [0/7664 (0%)]\tLoss: 0.661866\n",
      "Train Epoch: 5 [640/7664 (8%)]\tLoss: 0.666691\n",
      "Train Epoch: 5 [1280/7664 (17%)]\tLoss: 0.672288\n",
      "Train Epoch: 5 [1920/7664 (25%)]\tLoss: 0.645001\n",
      "Train Epoch: 5 [2560/7664 (33%)]\tLoss: 0.657032\n",
      "Train Epoch: 5 [3200/7664 (42%)]\tLoss: 0.658494\n",
      "Train Epoch: 5 [3840/7664 (50%)]\tLoss: 0.644509\n",
      "Train Epoch: 5 [4480/7664 (58%)]\tLoss: 0.601373\n",
      "Train Epoch: 5 [5120/7664 (67%)]\tLoss: 0.644440\n",
      "Train Epoch: 5 [5760/7664 (75%)]\tLoss: 0.609586\n",
      "Train Epoch: 5 [6400/7664 (83%)]\tLoss: 0.621876\n",
      "Train Epoch: 5 [7040/7664 (92%)]\tLoss: 0.616132\n",
      "\n",
      "Test set: Average loss: 0.5973, Accuracy: 1800/2396 (75%)\n",
      "\n",
      "Train Epoch: 6 [0/7664 (0%)]\tLoss: 0.584617\n",
      "Train Epoch: 6 [640/7664 (8%)]\tLoss: 0.607029\n",
      "Train Epoch: 6 [1280/7664 (17%)]\tLoss: 0.607805\n",
      "Train Epoch: 6 [1920/7664 (25%)]\tLoss: 0.531130\n",
      "Train Epoch: 6 [2560/7664 (33%)]\tLoss: 0.590287\n",
      "Train Epoch: 6 [3200/7664 (42%)]\tLoss: 0.601852\n",
      "Train Epoch: 6 [3840/7664 (50%)]\tLoss: 0.576571\n",
      "Train Epoch: 6 [4480/7664 (58%)]\tLoss: 0.430372\n",
      "Train Epoch: 6 [5120/7664 (67%)]\tLoss: 0.583465\n",
      "Train Epoch: 6 [5760/7664 (75%)]\tLoss: 0.493451\n",
      "Train Epoch: 6 [6400/7664 (83%)]\tLoss: 0.529794\n",
      "Train Epoch: 6 [7040/7664 (92%)]\tLoss: 0.562328\n",
      "\n",
      "Test set: Average loss: 0.5162, Accuracy: 1823/2396 (76%)\n",
      "\n",
      "Train Epoch: 7 [0/7664 (0%)]\tLoss: 0.496531\n",
      "Train Epoch: 7 [640/7664 (8%)]\tLoss: 0.550643\n",
      "Train Epoch: 7 [1280/7664 (17%)]\tLoss: 0.522964\n",
      "Train Epoch: 7 [1920/7664 (25%)]\tLoss: 0.461731\n",
      "Train Epoch: 7 [2560/7664 (33%)]\tLoss: 0.553892\n",
      "Train Epoch: 7 [3200/7664 (42%)]\tLoss: 0.561928\n",
      "Train Epoch: 7 [3840/7664 (50%)]\tLoss: 0.558296\n",
      "Train Epoch: 7 [4480/7664 (58%)]\tLoss: 0.359369\n",
      "Train Epoch: 7 [5120/7664 (67%)]\tLoss: 0.555396\n",
      "Train Epoch: 7 [5760/7664 (75%)]\tLoss: 0.454190\n",
      "Train Epoch: 7 [6400/7664 (83%)]\tLoss: 0.486941\n",
      "Train Epoch: 7 [7040/7664 (92%)]\tLoss: 0.553770\n",
      "\n",
      "Test set: Average loss: 0.4811, Accuracy: 1896/2396 (79%)\n",
      "\n",
      "Train Epoch: 8 [0/7664 (0%)]\tLoss: 0.456394\n",
      "Train Epoch: 8 [640/7664 (8%)]\tLoss: 0.538595\n",
      "Train Epoch: 8 [1280/7664 (17%)]\tLoss: 0.476024\n",
      "Train Epoch: 8 [1920/7664 (25%)]\tLoss: 0.440503\n",
      "Train Epoch: 8 [2560/7664 (33%)]\tLoss: 0.534779\n",
      "Train Epoch: 8 [3200/7664 (42%)]\tLoss: 0.535915\n",
      "Train Epoch: 8 [3840/7664 (50%)]\tLoss: 0.544077\n",
      "Train Epoch: 8 [4480/7664 (58%)]\tLoss: 0.333656\n",
      "Train Epoch: 8 [5120/7664 (67%)]\tLoss: 0.530935\n",
      "Train Epoch: 8 [5760/7664 (75%)]\tLoss: 0.431757\n",
      "Train Epoch: 8 [6400/7664 (83%)]\tLoss: 0.465955\n",
      "Train Epoch: 8 [7040/7664 (92%)]\tLoss: 0.549947\n",
      "\n",
      "Test set: Average loss: 0.4597, Accuracy: 1910/2396 (80%)\n",
      "\n",
      "Train Epoch: 9 [0/7664 (0%)]\tLoss: 0.431612\n",
      "Train Epoch: 9 [640/7664 (8%)]\tLoss: 0.534910\n",
      "Train Epoch: 9 [1280/7664 (17%)]\tLoss: 0.451021\n",
      "Train Epoch: 9 [1920/7664 (25%)]\tLoss: 0.424119\n",
      "Train Epoch: 9 [2560/7664 (33%)]\tLoss: 0.522815\n",
      "Train Epoch: 9 [3200/7664 (42%)]\tLoss: 0.527772\n",
      "Train Epoch: 9 [3840/7664 (50%)]\tLoss: 0.524494\n",
      "Train Epoch: 9 [4480/7664 (58%)]\tLoss: 0.322831\n",
      "Train Epoch: 9 [5120/7664 (67%)]\tLoss: 0.512979\n",
      "Train Epoch: 9 [5760/7664 (75%)]\tLoss: 0.416141\n",
      "Train Epoch: 9 [6400/7664 (83%)]\tLoss: 0.449670\n",
      "Train Epoch: 9 [7040/7664 (92%)]\tLoss: 0.541666\n",
      "\n",
      "Test set: Average loss: 0.4436, Accuracy: 1909/2396 (80%)\n",
      "\n",
      "Train Epoch: 10 [0/7664 (0%)]\tLoss: 0.414826\n",
      "Train Epoch: 10 [640/7664 (8%)]\tLoss: 0.528756\n",
      "Train Epoch: 10 [1280/7664 (17%)]\tLoss: 0.433540\n",
      "Train Epoch: 10 [1920/7664 (25%)]\tLoss: 0.406175\n",
      "Train Epoch: 10 [2560/7664 (33%)]\tLoss: 0.508651\n",
      "Train Epoch: 10 [3200/7664 (42%)]\tLoss: 0.525676\n",
      "Train Epoch: 10 [3840/7664 (50%)]\tLoss: 0.502565\n",
      "Train Epoch: 10 [4480/7664 (58%)]\tLoss: 0.318996\n",
      "Train Epoch: 10 [5120/7664 (67%)]\tLoss: 0.500264\n",
      "Train Epoch: 10 [5760/7664 (75%)]\tLoss: 0.403792\n",
      "Train Epoch: 10 [6400/7664 (83%)]\tLoss: 0.433019\n",
      "Train Epoch: 10 [7040/7664 (92%)]\tLoss: 0.528296\n",
      "\n",
      "Test set: Average loss: 0.4304, Accuracy: 1919/2396 (80%)\n",
      "\n",
      "Train Epoch: 11 [0/7664 (0%)]\tLoss: 0.402484\n",
      "Train Epoch: 11 [640/7664 (8%)]\tLoss: 0.519955\n",
      "Train Epoch: 11 [1280/7664 (17%)]\tLoss: 0.419005\n",
      "Train Epoch: 11 [1920/7664 (25%)]\tLoss: 0.387485\n",
      "Train Epoch: 11 [2560/7664 (33%)]\tLoss: 0.491308\n",
      "Train Epoch: 11 [3200/7664 (42%)]\tLoss: 0.525377\n",
      "Train Epoch: 11 [3840/7664 (50%)]\tLoss: 0.481821\n",
      "Train Epoch: 11 [4480/7664 (58%)]\tLoss: 0.316832\n",
      "Train Epoch: 11 [5120/7664 (67%)]\tLoss: 0.491228\n",
      "Train Epoch: 11 [5760/7664 (75%)]\tLoss: 0.393122\n",
      "Train Epoch: 11 [6400/7664 (83%)]\tLoss: 0.416022\n",
      "Train Epoch: 11 [7040/7664 (92%)]\tLoss: 0.514047\n",
      "\n",
      "Test set: Average loss: 0.4195, Accuracy: 1914/2396 (80%)\n",
      "\n",
      "Train Epoch: 12 [0/7664 (0%)]\tLoss: 0.392788\n",
      "Train Epoch: 12 [640/7664 (8%)]\tLoss: 0.509826\n",
      "Train Epoch: 12 [1280/7664 (17%)]\tLoss: 0.407111\n",
      "Train Epoch: 12 [1920/7664 (25%)]\tLoss: 0.368835\n",
      "Train Epoch: 12 [2560/7664 (33%)]\tLoss: 0.471300\n",
      "Train Epoch: 12 [3200/7664 (42%)]\tLoss: 0.525073\n",
      "Train Epoch: 12 [3840/7664 (50%)]\tLoss: 0.462766\n",
      "Train Epoch: 12 [4480/7664 (58%)]\tLoss: 0.312826\n",
      "Train Epoch: 12 [5120/7664 (67%)]\tLoss: 0.483536\n",
      "Train Epoch: 12 [5760/7664 (75%)]\tLoss: 0.383044\n",
      "Train Epoch: 12 [6400/7664 (83%)]\tLoss: 0.399313\n",
      "Train Epoch: 12 [7040/7664 (92%)]\tLoss: 0.500514\n",
      "\n",
      "Test set: Average loss: 0.4098, Accuracy: 1922/2396 (80%)\n",
      "\n",
      "Train Epoch: 13 [0/7664 (0%)]\tLoss: 0.383774\n",
      "Train Epoch: 13 [640/7664 (8%)]\tLoss: 0.498713\n",
      "Train Epoch: 13 [1280/7664 (17%)]\tLoss: 0.397685\n",
      "Train Epoch: 13 [1920/7664 (25%)]\tLoss: 0.350243\n",
      "Train Epoch: 13 [2560/7664 (33%)]\tLoss: 0.449230\n",
      "Train Epoch: 13 [3200/7664 (42%)]\tLoss: 0.522992\n",
      "Train Epoch: 13 [3840/7664 (50%)]\tLoss: 0.443999\n",
      "Train Epoch: 13 [4480/7664 (58%)]\tLoss: 0.305181\n",
      "Train Epoch: 13 [5120/7664 (67%)]\tLoss: 0.475953\n",
      "Train Epoch: 13 [5760/7664 (75%)]\tLoss: 0.371970\n",
      "Train Epoch: 13 [6400/7664 (83%)]\tLoss: 0.383429\n",
      "Train Epoch: 13 [7040/7664 (92%)]\tLoss: 0.487728\n",
      "\n",
      "Test set: Average loss: 0.4003, Accuracy: 1942/2396 (81%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [0/7664 (0%)]\tLoss: 0.373515\n",
      "Train Epoch: 14 [640/7664 (8%)]\tLoss: 0.486956\n",
      "Train Epoch: 14 [1280/7664 (17%)]\tLoss: 0.390034\n",
      "Train Epoch: 14 [1920/7664 (25%)]\tLoss: 0.331048\n",
      "Train Epoch: 14 [2560/7664 (33%)]\tLoss: 0.426113\n",
      "Train Epoch: 14 [3200/7664 (42%)]\tLoss: 0.518662\n",
      "Train Epoch: 14 [3840/7664 (50%)]\tLoss: 0.424618\n",
      "Train Epoch: 14 [4480/7664 (58%)]\tLoss: 0.294190\n",
      "Train Epoch: 14 [5120/7664 (67%)]\tLoss: 0.467874\n",
      "Train Epoch: 14 [5760/7664 (75%)]\tLoss: 0.359591\n",
      "Train Epoch: 14 [6400/7664 (83%)]\tLoss: 0.368960\n",
      "Train Epoch: 14 [7040/7664 (92%)]\tLoss: 0.475899\n",
      "\n",
      "Test set: Average loss: 0.3908, Accuracy: 1942/2396 (81%)\n",
      "\n",
      "Train Epoch: 15 [0/7664 (0%)]\tLoss: 0.360947\n",
      "Train Epoch: 15 [640/7664 (8%)]\tLoss: 0.474717\n",
      "Train Epoch: 15 [1280/7664 (17%)]\tLoss: 0.383665\n",
      "Train Epoch: 15 [1920/7664 (25%)]\tLoss: 0.312388\n",
      "Train Epoch: 15 [2560/7664 (33%)]\tLoss: 0.404184\n",
      "Train Epoch: 15 [3200/7664 (42%)]\tLoss: 0.512873\n",
      "Train Epoch: 15 [3840/7664 (50%)]\tLoss: 0.405498\n",
      "Train Epoch: 15 [4480/7664 (58%)]\tLoss: 0.281539\n",
      "Train Epoch: 15 [5120/7664 (67%)]\tLoss: 0.459933\n",
      "Train Epoch: 15 [5760/7664 (75%)]\tLoss: 0.346467\n",
      "Train Epoch: 15 [6400/7664 (83%)]\tLoss: 0.356057\n",
      "Train Epoch: 15 [7040/7664 (92%)]\tLoss: 0.465073\n",
      "\n",
      "Test set: Average loss: 0.3816, Accuracy: 1945/2396 (81%)\n",
      "\n",
      "Train Epoch: 16 [0/7664 (0%)]\tLoss: 0.346512\n",
      "Train Epoch: 16 [640/7664 (8%)]\tLoss: 0.462704\n",
      "Train Epoch: 16 [1280/7664 (17%)]\tLoss: 0.377906\n",
      "Train Epoch: 16 [1920/7664 (25%)]\tLoss: 0.295222\n",
      "Train Epoch: 16 [2560/7664 (33%)]\tLoss: 0.383605\n",
      "Train Epoch: 16 [3200/7664 (42%)]\tLoss: 0.504768\n",
      "Train Epoch: 16 [3840/7664 (50%)]\tLoss: 0.386566\n",
      "Train Epoch: 16 [4480/7664 (58%)]\tLoss: 0.268357\n",
      "Train Epoch: 16 [5120/7664 (67%)]\tLoss: 0.451873\n",
      "Train Epoch: 16 [5760/7664 (75%)]\tLoss: 0.332940\n",
      "Train Epoch: 16 [6400/7664 (83%)]\tLoss: 0.345219\n",
      "Train Epoch: 16 [7040/7664 (92%)]\tLoss: 0.454466\n",
      "\n",
      "Test set: Average loss: 0.3722, Accuracy: 1959/2396 (82%)\n",
      "\n",
      "Train Epoch: 17 [0/7664 (0%)]\tLoss: 0.330590\n",
      "Train Epoch: 17 [640/7664 (8%)]\tLoss: 0.451717\n",
      "Train Epoch: 17 [1280/7664 (17%)]\tLoss: 0.372136\n",
      "Train Epoch: 17 [1920/7664 (25%)]\tLoss: 0.280452\n",
      "Train Epoch: 17 [2560/7664 (33%)]\tLoss: 0.364790\n",
      "Train Epoch: 17 [3200/7664 (42%)]\tLoss: 0.495315\n",
      "Train Epoch: 17 [3840/7664 (50%)]\tLoss: 0.369107\n",
      "Train Epoch: 17 [4480/7664 (58%)]\tLoss: 0.255473\n",
      "Train Epoch: 17 [5120/7664 (67%)]\tLoss: 0.443403\n",
      "Train Epoch: 17 [5760/7664 (75%)]\tLoss: 0.319612\n",
      "Train Epoch: 17 [6400/7664 (83%)]\tLoss: 0.336903\n",
      "Train Epoch: 17 [7040/7664 (92%)]\tLoss: 0.444382\n",
      "\n",
      "Test set: Average loss: 0.3629, Accuracy: 1969/2396 (82%)\n",
      "\n",
      "Train Epoch: 18 [0/7664 (0%)]\tLoss: 0.313926\n",
      "Train Epoch: 18 [640/7664 (8%)]\tLoss: 0.442444\n",
      "Train Epoch: 18 [1280/7664 (17%)]\tLoss: 0.366704\n",
      "Train Epoch: 18 [1920/7664 (25%)]\tLoss: 0.268175\n",
      "Train Epoch: 18 [2560/7664 (33%)]\tLoss: 0.348882\n",
      "Train Epoch: 18 [3200/7664 (42%)]\tLoss: 0.485494\n",
      "Train Epoch: 18 [3840/7664 (50%)]\tLoss: 0.354145\n",
      "Train Epoch: 18 [4480/7664 (58%)]\tLoss: 0.243942\n",
      "Train Epoch: 18 [5120/7664 (67%)]\tLoss: 0.434983\n",
      "Train Epoch: 18 [5760/7664 (75%)]\tLoss: 0.307030\n",
      "Train Epoch: 18 [6400/7664 (83%)]\tLoss: 0.330681\n",
      "Train Epoch: 18 [7040/7664 (92%)]\tLoss: 0.434907\n",
      "\n",
      "Test set: Average loss: 0.3546, Accuracy: 1986/2396 (83%)\n",
      "\n",
      "Train Epoch: 19 [0/7664 (0%)]\tLoss: 0.297332\n",
      "Train Epoch: 19 [640/7664 (8%)]\tLoss: 0.434913\n",
      "Train Epoch: 19 [1280/7664 (17%)]\tLoss: 0.361345\n",
      "Train Epoch: 19 [1920/7664 (25%)]\tLoss: 0.258352\n",
      "Train Epoch: 19 [2560/7664 (33%)]\tLoss: 0.335979\n",
      "Train Epoch: 19 [3200/7664 (42%)]\tLoss: 0.475138\n",
      "Train Epoch: 19 [3840/7664 (50%)]\tLoss: 0.342782\n",
      "Train Epoch: 19 [4480/7664 (58%)]\tLoss: 0.234101\n",
      "Train Epoch: 19 [5120/7664 (67%)]\tLoss: 0.426885\n",
      "Train Epoch: 19 [5760/7664 (75%)]\tLoss: 0.295682\n",
      "Train Epoch: 19 [6400/7664 (83%)]\tLoss: 0.324965\n",
      "Train Epoch: 19 [7040/7664 (92%)]\tLoss: 0.426165\n",
      "\n",
      "Test set: Average loss: 0.3465, Accuracy: 1993/2396 (83%)\n",
      "\n",
      "Train Epoch: 20 [0/7664 (0%)]\tLoss: 0.281607\n",
      "Train Epoch: 20 [640/7664 (8%)]\tLoss: 0.428954\n",
      "Train Epoch: 20 [1280/7664 (17%)]\tLoss: 0.355540\n",
      "Train Epoch: 20 [1920/7664 (25%)]\tLoss: 0.250603\n",
      "Train Epoch: 20 [2560/7664 (33%)]\tLoss: 0.325640\n",
      "Train Epoch: 20 [3200/7664 (42%)]\tLoss: 0.465090\n",
      "Train Epoch: 20 [3840/7664 (50%)]\tLoss: 0.334147\n",
      "Train Epoch: 20 [4480/7664 (58%)]\tLoss: 0.225451\n",
      "Train Epoch: 20 [5120/7664 (67%)]\tLoss: 0.419249\n",
      "Train Epoch: 20 [5760/7664 (75%)]\tLoss: 0.286295\n",
      "Train Epoch: 20 [6400/7664 (83%)]\tLoss: 0.319457\n",
      "Train Epoch: 20 [7040/7664 (92%)]\tLoss: 0.419686\n",
      "\n",
      "Test set: Average loss: 0.3395, Accuracy: 1994/2396 (83%)\n",
      "\n",
      "Train Epoch: 21 [0/7664 (0%)]\tLoss: 0.268275\n",
      "Train Epoch: 21 [640/7664 (8%)]\tLoss: 0.424671\n",
      "Train Epoch: 21 [1280/7664 (17%)]\tLoss: 0.349309\n",
      "Train Epoch: 21 [1920/7664 (25%)]\tLoss: 0.244594\n",
      "Train Epoch: 21 [2560/7664 (33%)]\tLoss: 0.317198\n",
      "Train Epoch: 21 [3200/7664 (42%)]\tLoss: 0.454298\n",
      "Train Epoch: 21 [3840/7664 (50%)]\tLoss: 0.327917\n",
      "Train Epoch: 21 [4480/7664 (58%)]\tLoss: 0.218416\n",
      "Train Epoch: 21 [5120/7664 (67%)]\tLoss: 0.412231\n",
      "Train Epoch: 21 [5760/7664 (75%)]\tLoss: 0.278170\n",
      "Train Epoch: 21 [6400/7664 (83%)]\tLoss: 0.314319\n",
      "Train Epoch: 21 [7040/7664 (92%)]\tLoss: 0.414303\n",
      "\n",
      "Test set: Average loss: 0.3331, Accuracy: 2007/2396 (84%)\n",
      "\n",
      "Train Epoch: 22 [0/7664 (0%)]\tLoss: 0.256979\n",
      "Train Epoch: 22 [640/7664 (8%)]\tLoss: 0.421288\n",
      "Train Epoch: 22 [1280/7664 (17%)]\tLoss: 0.342644\n",
      "Train Epoch: 22 [1920/7664 (25%)]\tLoss: 0.240041\n",
      "Train Epoch: 22 [2560/7664 (33%)]\tLoss: 0.310433\n",
      "Train Epoch: 22 [3200/7664 (42%)]\tLoss: 0.443668\n",
      "Train Epoch: 22 [3840/7664 (50%)]\tLoss: 0.323874\n",
      "Train Epoch: 22 [4480/7664 (58%)]\tLoss: 0.212383\n",
      "Train Epoch: 22 [5120/7664 (67%)]\tLoss: 0.405329\n",
      "Train Epoch: 22 [5760/7664 (75%)]\tLoss: 0.270212\n",
      "Train Epoch: 22 [6400/7664 (83%)]\tLoss: 0.309684\n",
      "Train Epoch: 22 [7040/7664 (92%)]\tLoss: 0.410568\n",
      "\n",
      "Test set: Average loss: 0.3270, Accuracy: 2019/2396 (84%)\n",
      "\n",
      "Train Epoch: 23 [0/7664 (0%)]\tLoss: 0.246866\n",
      "Train Epoch: 23 [640/7664 (8%)]\tLoss: 0.418331\n",
      "Train Epoch: 23 [1280/7664 (17%)]\tLoss: 0.335625\n",
      "Train Epoch: 23 [1920/7664 (25%)]\tLoss: 0.236097\n",
      "Train Epoch: 23 [2560/7664 (33%)]\tLoss: 0.304747\n",
      "Train Epoch: 23 [3200/7664 (42%)]\tLoss: 0.433436\n",
      "Train Epoch: 23 [3840/7664 (50%)]\tLoss: 0.320946\n",
      "Train Epoch: 23 [4480/7664 (58%)]\tLoss: 0.207206\n",
      "Train Epoch: 23 [5120/7664 (67%)]\tLoss: 0.398596\n",
      "Train Epoch: 23 [5760/7664 (75%)]\tLoss: 0.262736\n",
      "Train Epoch: 23 [6400/7664 (83%)]\tLoss: 0.305434\n",
      "Train Epoch: 23 [7040/7664 (92%)]\tLoss: 0.406355\n",
      "\n",
      "Test set: Average loss: 0.3211, Accuracy: 2028/2396 (85%)\n",
      "\n",
      "Train Epoch: 24 [0/7664 (0%)]\tLoss: 0.237543\n",
      "Train Epoch: 24 [640/7664 (8%)]\tLoss: 0.415438\n",
      "Train Epoch: 24 [1280/7664 (17%)]\tLoss: 0.328773\n",
      "Train Epoch: 24 [1920/7664 (25%)]\tLoss: 0.232711\n",
      "Train Epoch: 24 [2560/7664 (33%)]\tLoss: 0.299535\n",
      "Train Epoch: 24 [3200/7664 (42%)]\tLoss: 0.424045\n",
      "Train Epoch: 24 [3840/7664 (50%)]\tLoss: 0.318958\n",
      "Train Epoch: 24 [4480/7664 (58%)]\tLoss: 0.202202\n",
      "Train Epoch: 24 [5120/7664 (67%)]\tLoss: 0.392039\n",
      "Train Epoch: 24 [5760/7664 (75%)]\tLoss: 0.255801\n",
      "Train Epoch: 24 [6400/7664 (83%)]\tLoss: 0.301247\n",
      "Train Epoch: 24 [7040/7664 (92%)]\tLoss: 0.402925\n",
      "\n",
      "Test set: Average loss: 0.3153, Accuracy: 2038/2396 (85%)\n",
      "\n",
      "Train Epoch: 25 [0/7664 (0%)]\tLoss: 0.229262\n",
      "Train Epoch: 25 [640/7664 (8%)]\tLoss: 0.412168\n",
      "Train Epoch: 25 [1280/7664 (17%)]\tLoss: 0.322530\n",
      "Train Epoch: 25 [1920/7664 (25%)]\tLoss: 0.228358\n",
      "Train Epoch: 25 [2560/7664 (33%)]\tLoss: 0.294375\n",
      "Train Epoch: 25 [3200/7664 (42%)]\tLoss: 0.414002\n",
      "Train Epoch: 25 [3840/7664 (50%)]\tLoss: 0.317576\n",
      "Train Epoch: 25 [4480/7664 (58%)]\tLoss: 0.197705\n",
      "Train Epoch: 25 [5120/7664 (67%)]\tLoss: 0.385529\n",
      "Train Epoch: 25 [5760/7664 (75%)]\tLoss: 0.248999\n",
      "Train Epoch: 25 [6400/7664 (83%)]\tLoss: 0.297084\n",
      "Train Epoch: 25 [7040/7664 (92%)]\tLoss: 0.400735\n",
      "\n",
      "Test set: Average loss: 0.3098, Accuracy: 2045/2396 (85%)\n",
      "\n",
      "Train Epoch: 26 [0/7664 (0%)]\tLoss: 0.221536\n",
      "Train Epoch: 26 [640/7664 (8%)]\tLoss: 0.408931\n",
      "Train Epoch: 26 [1280/7664 (17%)]\tLoss: 0.315741\n",
      "Train Epoch: 26 [1920/7664 (25%)]\tLoss: 0.225305\n",
      "Train Epoch: 26 [2560/7664 (33%)]\tLoss: 0.289295\n",
      "Train Epoch: 26 [3200/7664 (42%)]\tLoss: 0.405899\n",
      "Train Epoch: 26 [3840/7664 (50%)]\tLoss: 0.316372\n",
      "Train Epoch: 26 [4480/7664 (58%)]\tLoss: 0.193697\n",
      "Train Epoch: 26 [5120/7664 (67%)]\tLoss: 0.379319\n",
      "Train Epoch: 26 [5760/7664 (75%)]\tLoss: 0.242731\n",
      "Train Epoch: 26 [6400/7664 (83%)]\tLoss: 0.293052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [7040/7664 (92%)]\tLoss: 0.399256\n",
      "\n",
      "Test set: Average loss: 0.3044, Accuracy: 2055/2396 (86%)\n",
      "\n",
      "Train Epoch: 27 [0/7664 (0%)]\tLoss: 0.214623\n",
      "Train Epoch: 27 [640/7664 (8%)]\tLoss: 0.405307\n",
      "Train Epoch: 27 [1280/7664 (17%)]\tLoss: 0.308908\n",
      "Train Epoch: 27 [1920/7664 (25%)]\tLoss: 0.221991\n",
      "Train Epoch: 27 [2560/7664 (33%)]\tLoss: 0.283983\n",
      "Train Epoch: 27 [3200/7664 (42%)]\tLoss: 0.397584\n",
      "Train Epoch: 27 [3840/7664 (50%)]\tLoss: 0.315455\n",
      "Train Epoch: 27 [4480/7664 (58%)]\tLoss: 0.190392\n",
      "Train Epoch: 27 [5120/7664 (67%)]\tLoss: 0.372740\n",
      "Train Epoch: 27 [5760/7664 (75%)]\tLoss: 0.236591\n",
      "Train Epoch: 27 [6400/7664 (83%)]\tLoss: 0.289362\n",
      "Train Epoch: 27 [7040/7664 (92%)]\tLoss: 0.398599\n",
      "\n",
      "Test set: Average loss: 0.2991, Accuracy: 2059/2396 (86%)\n",
      "\n",
      "Train Epoch: 28 [0/7664 (0%)]\tLoss: 0.207938\n",
      "Train Epoch: 28 [640/7664 (8%)]\tLoss: 0.401619\n",
      "Train Epoch: 28 [1280/7664 (17%)]\tLoss: 0.302255\n",
      "Train Epoch: 28 [1920/7664 (25%)]\tLoss: 0.217803\n",
      "Train Epoch: 28 [2560/7664 (33%)]\tLoss: 0.279563\n",
      "Train Epoch: 28 [3200/7664 (42%)]\tLoss: 0.391353\n",
      "Train Epoch: 28 [3840/7664 (50%)]\tLoss: 0.314108\n",
      "Train Epoch: 28 [4480/7664 (58%)]\tLoss: 0.187147\n",
      "Train Epoch: 28 [5120/7664 (67%)]\tLoss: 0.366595\n",
      "Train Epoch: 28 [5760/7664 (75%)]\tLoss: 0.230992\n",
      "Train Epoch: 28 [6400/7664 (83%)]\tLoss: 0.284709\n",
      "Train Epoch: 28 [7040/7664 (92%)]\tLoss: 0.394818\n",
      "\n",
      "Test set: Average loss: 0.2939, Accuracy: 2065/2396 (86%)\n",
      "\n",
      "Train Epoch: 29 [0/7664 (0%)]\tLoss: 0.201921\n",
      "Train Epoch: 29 [640/7664 (8%)]\tLoss: 0.397441\n",
      "Train Epoch: 29 [1280/7664 (17%)]\tLoss: 0.296398\n",
      "Train Epoch: 29 [1920/7664 (25%)]\tLoss: 0.208741\n",
      "Train Epoch: 29 [2560/7664 (33%)]\tLoss: 0.275156\n",
      "Train Epoch: 29 [3200/7664 (42%)]\tLoss: 0.384258\n",
      "Train Epoch: 29 [3840/7664 (50%)]\tLoss: 0.313249\n",
      "Train Epoch: 29 [4480/7664 (58%)]\tLoss: 0.184210\n",
      "Train Epoch: 29 [5120/7664 (67%)]\tLoss: 0.360549\n",
      "Train Epoch: 29 [5760/7664 (75%)]\tLoss: 0.226187\n",
      "Train Epoch: 29 [6400/7664 (83%)]\tLoss: 0.281729\n",
      "Train Epoch: 29 [7040/7664 (92%)]\tLoss: 0.397311\n",
      "\n",
      "Test set: Average loss: 0.2891, Accuracy: 2072/2396 (86%)\n",
      "\n",
      "Train Epoch: 30 [0/7664 (0%)]\tLoss: 0.197170\n",
      "Train Epoch: 30 [640/7664 (8%)]\tLoss: 0.393189\n",
      "Train Epoch: 30 [1280/7664 (17%)]\tLoss: 0.290221\n",
      "Train Epoch: 30 [1920/7664 (25%)]\tLoss: 0.204673\n",
      "Train Epoch: 30 [2560/7664 (33%)]\tLoss: 0.270071\n",
      "Train Epoch: 30 [3200/7664 (42%)]\tLoss: 0.376889\n",
      "Train Epoch: 30 [3840/7664 (50%)]\tLoss: 0.313664\n",
      "Train Epoch: 30 [4480/7664 (58%)]\tLoss: 0.181867\n",
      "Train Epoch: 30 [5120/7664 (67%)]\tLoss: 0.354965\n",
      "Train Epoch: 30 [5760/7664 (75%)]\tLoss: 0.221270\n",
      "Train Epoch: 30 [6400/7664 (83%)]\tLoss: 0.277387\n",
      "Train Epoch: 30 [7040/7664 (92%)]\tLoss: 0.390803\n",
      "\n",
      "Test set: Average loss: 0.2832, Accuracy: 2073/2396 (87%)\n",
      "\n",
      "Train Epoch: 31 [0/7664 (0%)]\tLoss: 0.191378\n",
      "Train Epoch: 31 [640/7664 (8%)]\tLoss: 0.388139\n",
      "Train Epoch: 31 [1280/7664 (17%)]\tLoss: 0.284079\n",
      "Train Epoch: 31 [1920/7664 (25%)]\tLoss: 0.200844\n",
      "Train Epoch: 31 [2560/7664 (33%)]\tLoss: 0.265871\n",
      "Train Epoch: 31 [3200/7664 (42%)]\tLoss: 0.370293\n",
      "Train Epoch: 31 [3840/7664 (50%)]\tLoss: 0.312940\n",
      "Train Epoch: 31 [4480/7664 (58%)]\tLoss: 0.179086\n",
      "Train Epoch: 31 [5120/7664 (67%)]\tLoss: 0.348906\n",
      "Train Epoch: 31 [5760/7664 (75%)]\tLoss: 0.216564\n",
      "Train Epoch: 31 [6400/7664 (83%)]\tLoss: 0.273980\n",
      "Train Epoch: 31 [7040/7664 (92%)]\tLoss: 0.390539\n",
      "\n",
      "Test set: Average loss: 0.2779, Accuracy: 2078/2396 (87%)\n",
      "\n",
      "Train Epoch: 32 [0/7664 (0%)]\tLoss: 0.186432\n",
      "Train Epoch: 32 [640/7664 (8%)]\tLoss: 0.383092\n",
      "Train Epoch: 32 [1280/7664 (17%)]\tLoss: 0.277776\n",
      "Train Epoch: 32 [1920/7664 (25%)]\tLoss: 0.196793\n",
      "Train Epoch: 32 [2560/7664 (33%)]\tLoss: 0.260746\n",
      "Train Epoch: 32 [3200/7664 (42%)]\tLoss: 0.362127\n",
      "Train Epoch: 32 [3840/7664 (50%)]\tLoss: 0.312066\n",
      "Train Epoch: 32 [4480/7664 (58%)]\tLoss: 0.177023\n",
      "Train Epoch: 32 [5120/7664 (67%)]\tLoss: 0.342540\n",
      "Train Epoch: 32 [5760/7664 (75%)]\tLoss: 0.212579\n",
      "Train Epoch: 32 [6400/7664 (83%)]\tLoss: 0.271679\n",
      "Train Epoch: 32 [7040/7664 (92%)]\tLoss: 0.401544\n",
      "\n",
      "Test set: Average loss: 0.2739, Accuracy: 2084/2396 (87%)\n",
      "\n",
      "Train Epoch: 33 [0/7664 (0%)]\tLoss: 0.183280\n",
      "Train Epoch: 33 [640/7664 (8%)]\tLoss: 0.379583\n",
      "Train Epoch: 33 [1280/7664 (17%)]\tLoss: 0.272731\n",
      "Train Epoch: 33 [1920/7664 (25%)]\tLoss: 0.191082\n",
      "Train Epoch: 33 [2560/7664 (33%)]\tLoss: 0.255413\n",
      "Train Epoch: 33 [3200/7664 (42%)]\tLoss: 0.356158\n",
      "Train Epoch: 33 [3840/7664 (50%)]\tLoss: 0.311345\n",
      "Train Epoch: 33 [4480/7664 (58%)]\tLoss: 0.174803\n",
      "Train Epoch: 33 [5120/7664 (67%)]\tLoss: 0.336966\n",
      "Train Epoch: 33 [5760/7664 (75%)]\tLoss: 0.208343\n",
      "Train Epoch: 33 [6400/7664 (83%)]\tLoss: 0.268646\n",
      "Train Epoch: 33 [7040/7664 (92%)]\tLoss: 0.400696\n",
      "\n",
      "Test set: Average loss: 0.2693, Accuracy: 2097/2396 (88%)\n",
      "\n",
      "Train Epoch: 34 [0/7664 (0%)]\tLoss: 0.179122\n",
      "Train Epoch: 34 [640/7664 (8%)]\tLoss: 0.373728\n",
      "Train Epoch: 34 [1280/7664 (17%)]\tLoss: 0.267615\n",
      "Train Epoch: 34 [1920/7664 (25%)]\tLoss: 0.185667\n",
      "Train Epoch: 34 [2560/7664 (33%)]\tLoss: 0.250361\n",
      "Train Epoch: 34 [3200/7664 (42%)]\tLoss: 0.349192\n",
      "Train Epoch: 34 [3840/7664 (50%)]\tLoss: 0.310603\n",
      "Train Epoch: 34 [4480/7664 (58%)]\tLoss: 0.172869\n",
      "Train Epoch: 34 [5120/7664 (67%)]\tLoss: 0.331534\n",
      "Train Epoch: 34 [5760/7664 (75%)]\tLoss: 0.203567\n",
      "Train Epoch: 34 [6400/7664 (83%)]\tLoss: 0.265111\n",
      "Train Epoch: 34 [7040/7664 (92%)]\tLoss: 0.400894\n",
      "\n",
      "Test set: Average loss: 0.2649, Accuracy: 2107/2396 (88%)\n",
      "\n",
      "Train Epoch: 35 [0/7664 (0%)]\tLoss: 0.175104\n",
      "Train Epoch: 35 [640/7664 (8%)]\tLoss: 0.368914\n",
      "Train Epoch: 35 [1280/7664 (17%)]\tLoss: 0.262812\n",
      "Train Epoch: 35 [1920/7664 (25%)]\tLoss: 0.181222\n",
      "Train Epoch: 35 [2560/7664 (33%)]\tLoss: 0.245239\n",
      "Train Epoch: 35 [3200/7664 (42%)]\tLoss: 0.342096\n",
      "Train Epoch: 35 [3840/7664 (50%)]\tLoss: 0.310878\n",
      "Train Epoch: 35 [4480/7664 (58%)]\tLoss: 0.171087\n",
      "Train Epoch: 35 [5120/7664 (67%)]\tLoss: 0.325538\n",
      "Train Epoch: 35 [5760/7664 (75%)]\tLoss: 0.198917\n",
      "Train Epoch: 35 [6400/7664 (83%)]\tLoss: 0.261335\n",
      "Train Epoch: 35 [7040/7664 (92%)]\tLoss: 0.397340\n",
      "\n",
      "Test set: Average loss: 0.2615, Accuracy: 2113/2396 (88%)\n",
      "\n",
      "Train Epoch: 36 [0/7664 (0%)]\tLoss: 0.171730\n",
      "Train Epoch: 36 [640/7664 (8%)]\tLoss: 0.363325\n",
      "Train Epoch: 36 [1280/7664 (17%)]\tLoss: 0.258510\n",
      "Train Epoch: 36 [1920/7664 (25%)]\tLoss: 0.177310\n",
      "Train Epoch: 36 [2560/7664 (33%)]\tLoss: 0.240076\n",
      "Train Epoch: 36 [3200/7664 (42%)]\tLoss: 0.336458\n",
      "Train Epoch: 36 [3840/7664 (50%)]\tLoss: 0.309195\n",
      "Train Epoch: 36 [4480/7664 (58%)]\tLoss: 0.169134\n",
      "Train Epoch: 36 [5120/7664 (67%)]\tLoss: 0.319685\n",
      "Train Epoch: 36 [5760/7664 (75%)]\tLoss: 0.195171\n",
      "Train Epoch: 36 [6400/7664 (83%)]\tLoss: 0.257108\n",
      "Train Epoch: 36 [7040/7664 (92%)]\tLoss: 0.405393\n",
      "\n",
      "Test set: Average loss: 0.2580, Accuracy: 2117/2396 (88%)\n",
      "\n",
      "Train Epoch: 37 [0/7664 (0%)]\tLoss: 0.168825\n",
      "Train Epoch: 37 [640/7664 (8%)]\tLoss: 0.357201\n",
      "Train Epoch: 37 [1280/7664 (17%)]\tLoss: 0.254344\n",
      "Train Epoch: 37 [1920/7664 (25%)]\tLoss: 0.170155\n",
      "Train Epoch: 37 [2560/7664 (33%)]\tLoss: 0.235655\n",
      "Train Epoch: 37 [3200/7664 (42%)]\tLoss: 0.329292\n",
      "Train Epoch: 37 [3840/7664 (50%)]\tLoss: 0.307770\n",
      "Train Epoch: 37 [4480/7664 (58%)]\tLoss: 0.167974\n",
      "Train Epoch: 37 [5120/7664 (67%)]\tLoss: 0.313468\n",
      "Train Epoch: 37 [5760/7664 (75%)]\tLoss: 0.190650\n",
      "Train Epoch: 37 [6400/7664 (83%)]\tLoss: 0.253814\n",
      "Train Epoch: 37 [7040/7664 (92%)]\tLoss: 0.392416\n",
      "\n",
      "Test set: Average loss: 0.2539, Accuracy: 2125/2396 (89%)\n",
      "\n",
      "Train Epoch: 38 [0/7664 (0%)]\tLoss: 0.164579\n",
      "Train Epoch: 38 [640/7664 (8%)]\tLoss: 0.351809\n",
      "Train Epoch: 38 [1280/7664 (17%)]\tLoss: 0.249579\n",
      "Train Epoch: 38 [1920/7664 (25%)]\tLoss: 0.166263\n",
      "Train Epoch: 38 [2560/7664 (33%)]\tLoss: 0.230212\n",
      "Train Epoch: 38 [3200/7664 (42%)]\tLoss: 0.323496\n",
      "Train Epoch: 38 [3840/7664 (50%)]\tLoss: 0.307602\n",
      "Train Epoch: 38 [4480/7664 (58%)]\tLoss: 0.166509\n",
      "Train Epoch: 38 [5120/7664 (67%)]\tLoss: 0.309317\n",
      "Train Epoch: 38 [5760/7664 (75%)]\tLoss: 0.187355\n",
      "Train Epoch: 38 [6400/7664 (83%)]\tLoss: 0.250036\n",
      "Train Epoch: 38 [7040/7664 (92%)]\tLoss: 0.400805\n",
      "\n",
      "Test set: Average loss: 0.2511, Accuracy: 2128/2396 (89%)\n",
      "\n",
      "Train Epoch: 39 [0/7664 (0%)]\tLoss: 0.163109\n",
      "Train Epoch: 39 [640/7664 (8%)]\tLoss: 0.346277\n",
      "Train Epoch: 39 [1280/7664 (17%)]\tLoss: 0.247583\n",
      "Train Epoch: 39 [1920/7664 (25%)]\tLoss: 0.163542\n",
      "Train Epoch: 39 [2560/7664 (33%)]\tLoss: 0.225381\n",
      "Train Epoch: 39 [3200/7664 (42%)]\tLoss: 0.317968\n",
      "Train Epoch: 39 [3840/7664 (50%)]\tLoss: 0.304805\n",
      "Train Epoch: 39 [4480/7664 (58%)]\tLoss: 0.164906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [5120/7664 (67%)]\tLoss: 0.304041\n",
      "Train Epoch: 39 [5760/7664 (75%)]\tLoss: 0.182775\n",
      "Train Epoch: 39 [6400/7664 (83%)]\tLoss: 0.246064\n",
      "Train Epoch: 39 [7040/7664 (92%)]\tLoss: 0.396635\n",
      "\n",
      "Test set: Average loss: 0.2478, Accuracy: 2130/2396 (89%)\n",
      "\n",
      "Train Epoch: 40 [0/7664 (0%)]\tLoss: 0.160138\n",
      "Train Epoch: 40 [640/7664 (8%)]\tLoss: 0.340049\n",
      "Train Epoch: 40 [1280/7664 (17%)]\tLoss: 0.244713\n",
      "Train Epoch: 40 [1920/7664 (25%)]\tLoss: 0.159069\n",
      "Train Epoch: 40 [2560/7664 (33%)]\tLoss: 0.220411\n",
      "Train Epoch: 40 [3200/7664 (42%)]\tLoss: 0.312574\n",
      "Train Epoch: 40 [3840/7664 (50%)]\tLoss: 0.304633\n",
      "Train Epoch: 40 [4480/7664 (58%)]\tLoss: 0.163330\n",
      "Train Epoch: 40 [5120/7664 (67%)]\tLoss: 0.296846\n",
      "Train Epoch: 40 [5760/7664 (75%)]\tLoss: 0.179453\n",
      "Train Epoch: 40 [6400/7664 (83%)]\tLoss: 0.242372\n",
      "Train Epoch: 40 [7040/7664 (92%)]\tLoss: 0.404277\n",
      "\n",
      "Test set: Average loss: 0.2452, Accuracy: 2136/2396 (89%)\n",
      "\n",
      "Train Epoch: 41 [0/7664 (0%)]\tLoss: 0.158934\n",
      "Train Epoch: 41 [640/7664 (8%)]\tLoss: 0.336056\n",
      "Train Epoch: 41 [1280/7664 (17%)]\tLoss: 0.243251\n",
      "Train Epoch: 41 [1920/7664 (25%)]\tLoss: 0.155811\n",
      "Train Epoch: 41 [2560/7664 (33%)]\tLoss: 0.215980\n",
      "Train Epoch: 41 [3200/7664 (42%)]\tLoss: 0.306797\n",
      "Train Epoch: 41 [3840/7664 (50%)]\tLoss: 0.301321\n",
      "Train Epoch: 41 [4480/7664 (58%)]\tLoss: 0.161748\n",
      "Train Epoch: 41 [5120/7664 (67%)]\tLoss: 0.294062\n",
      "Train Epoch: 41 [5760/7664 (75%)]\tLoss: 0.174899\n",
      "Train Epoch: 41 [6400/7664 (83%)]\tLoss: 0.239097\n",
      "Train Epoch: 41 [7040/7664 (92%)]\tLoss: 0.401278\n",
      "\n",
      "Test set: Average loss: 0.2421, Accuracy: 2144/2396 (89%)\n",
      "\n",
      "Train Epoch: 42 [0/7664 (0%)]\tLoss: 0.156012\n",
      "Train Epoch: 42 [640/7664 (8%)]\tLoss: 0.329251\n",
      "Train Epoch: 42 [1280/7664 (17%)]\tLoss: 0.240485\n",
      "Train Epoch: 42 [1920/7664 (25%)]\tLoss: 0.154401\n",
      "Train Epoch: 42 [2560/7664 (33%)]\tLoss: 0.210873\n",
      "Train Epoch: 42 [3200/7664 (42%)]\tLoss: 0.301915\n",
      "Train Epoch: 42 [3840/7664 (50%)]\tLoss: 0.300233\n",
      "Train Epoch: 42 [4480/7664 (58%)]\tLoss: 0.159615\n",
      "Train Epoch: 42 [5120/7664 (67%)]\tLoss: 0.289560\n",
      "Train Epoch: 42 [5760/7664 (75%)]\tLoss: 0.171499\n",
      "Train Epoch: 42 [6400/7664 (83%)]\tLoss: 0.235335\n",
      "Train Epoch: 42 [7040/7664 (92%)]\tLoss: 0.404861\n",
      "\n",
      "Test set: Average loss: 0.2403, Accuracy: 2147/2396 (90%)\n",
      "\n",
      "Train Epoch: 43 [0/7664 (0%)]\tLoss: 0.155346\n",
      "Train Epoch: 43 [640/7664 (8%)]\tLoss: 0.325895\n",
      "Train Epoch: 43 [1280/7664 (17%)]\tLoss: 0.238572\n",
      "Train Epoch: 43 [1920/7664 (25%)]\tLoss: 0.149583\n",
      "Train Epoch: 43 [2560/7664 (33%)]\tLoss: 0.206418\n",
      "Train Epoch: 43 [3200/7664 (42%)]\tLoss: 0.296031\n",
      "Train Epoch: 43 [3840/7664 (50%)]\tLoss: 0.298320\n",
      "Train Epoch: 43 [4480/7664 (58%)]\tLoss: 0.157801\n",
      "Train Epoch: 43 [5120/7664 (67%)]\tLoss: 0.282163\n",
      "Train Epoch: 43 [5760/7664 (75%)]\tLoss: 0.167382\n",
      "Train Epoch: 43 [6400/7664 (83%)]\tLoss: 0.232609\n",
      "Train Epoch: 43 [7040/7664 (92%)]\tLoss: 0.401133\n",
      "\n",
      "Test set: Average loss: 0.2377, Accuracy: 2147/2396 (90%)\n",
      "\n",
      "Train Epoch: 44 [0/7664 (0%)]\tLoss: 0.151884\n",
      "Train Epoch: 44 [640/7664 (8%)]\tLoss: 0.319749\n",
      "Train Epoch: 44 [1280/7664 (17%)]\tLoss: 0.236095\n",
      "Train Epoch: 44 [1920/7664 (25%)]\tLoss: 0.145679\n",
      "Train Epoch: 44 [2560/7664 (33%)]\tLoss: 0.201465\n",
      "Train Epoch: 44 [3200/7664 (42%)]\tLoss: 0.291201\n",
      "Train Epoch: 44 [3840/7664 (50%)]\tLoss: 0.295310\n",
      "Train Epoch: 44 [4480/7664 (58%)]\tLoss: 0.155943\n",
      "Train Epoch: 44 [5120/7664 (67%)]\tLoss: 0.280039\n",
      "Train Epoch: 44 [5760/7664 (75%)]\tLoss: 0.164493\n",
      "Train Epoch: 44 [6400/7664 (83%)]\tLoss: 0.230817\n",
      "Train Epoch: 44 [7040/7664 (92%)]\tLoss: 0.401709\n",
      "\n",
      "Test set: Average loss: 0.2357, Accuracy: 2149/2396 (90%)\n",
      "\n",
      "Train Epoch: 45 [0/7664 (0%)]\tLoss: 0.149677\n",
      "Train Epoch: 45 [640/7664 (8%)]\tLoss: 0.316586\n",
      "Train Epoch: 45 [1280/7664 (17%)]\tLoss: 0.235004\n",
      "Train Epoch: 45 [1920/7664 (25%)]\tLoss: 0.146225\n",
      "Train Epoch: 45 [2560/7664 (33%)]\tLoss: 0.197027\n",
      "Train Epoch: 45 [3200/7664 (42%)]\tLoss: 0.285443\n",
      "Train Epoch: 45 [3840/7664 (50%)]\tLoss: 0.294200\n",
      "Train Epoch: 45 [4480/7664 (58%)]\tLoss: 0.154021\n",
      "Train Epoch: 45 [5120/7664 (67%)]\tLoss: 0.280368\n",
      "Train Epoch: 45 [5760/7664 (75%)]\tLoss: 0.161959\n",
      "Train Epoch: 45 [6400/7664 (83%)]\tLoss: 0.227506\n",
      "Train Epoch: 45 [7040/7664 (92%)]\tLoss: 0.406661\n",
      "\n",
      "Test set: Average loss: 0.2337, Accuracy: 2150/2396 (90%)\n",
      "\n",
      "Train Epoch: 46 [0/7664 (0%)]\tLoss: 0.148472\n",
      "Train Epoch: 46 [640/7664 (8%)]\tLoss: 0.313387\n",
      "Train Epoch: 46 [1280/7664 (17%)]\tLoss: 0.234006\n",
      "Train Epoch: 46 [1920/7664 (25%)]\tLoss: 0.142740\n",
      "Train Epoch: 46 [2560/7664 (33%)]\tLoss: 0.193216\n",
      "Train Epoch: 46 [3200/7664 (42%)]\tLoss: 0.280370\n",
      "Train Epoch: 46 [3840/7664 (50%)]\tLoss: 0.288878\n",
      "Train Epoch: 46 [4480/7664 (58%)]\tLoss: 0.152211\n",
      "Train Epoch: 46 [5120/7664 (67%)]\tLoss: 0.273084\n",
      "Train Epoch: 46 [5760/7664 (75%)]\tLoss: 0.159423\n",
      "Train Epoch: 46 [6400/7664 (83%)]\tLoss: 0.224809\n",
      "Train Epoch: 46 [7040/7664 (92%)]\tLoss: 0.406334\n",
      "\n",
      "Test set: Average loss: 0.2314, Accuracy: 2149/2396 (90%)\n",
      "\n",
      "Train Epoch: 47 [0/7664 (0%)]\tLoss: 0.145979\n",
      "Train Epoch: 47 [640/7664 (8%)]\tLoss: 0.309798\n",
      "Train Epoch: 47 [1280/7664 (17%)]\tLoss: 0.233066\n",
      "Train Epoch: 47 [1920/7664 (25%)]\tLoss: 0.140366\n",
      "Train Epoch: 47 [2560/7664 (33%)]\tLoss: 0.187973\n",
      "Train Epoch: 47 [3200/7664 (42%)]\tLoss: 0.276140\n",
      "Train Epoch: 47 [3840/7664 (50%)]\tLoss: 0.287252\n",
      "Train Epoch: 47 [4480/7664 (58%)]\tLoss: 0.150167\n",
      "Train Epoch: 47 [5120/7664 (67%)]\tLoss: 0.266679\n",
      "Train Epoch: 47 [5760/7664 (75%)]\tLoss: 0.156727\n",
      "Train Epoch: 47 [6400/7664 (83%)]\tLoss: 0.222631\n",
      "Train Epoch: 47 [7040/7664 (92%)]\tLoss: 0.404155\n",
      "\n",
      "Test set: Average loss: 0.2296, Accuracy: 2147/2396 (90%)\n",
      "\n",
      "Train Epoch: 48 [0/7664 (0%)]\tLoss: 0.144170\n",
      "Train Epoch: 48 [640/7664 (8%)]\tLoss: 0.306208\n",
      "Train Epoch: 48 [1280/7664 (17%)]\tLoss: 0.230469\n",
      "Train Epoch: 48 [1920/7664 (25%)]\tLoss: 0.139800\n",
      "Train Epoch: 48 [2560/7664 (33%)]\tLoss: 0.184304\n",
      "Train Epoch: 48 [3200/7664 (42%)]\tLoss: 0.270809\n",
      "Train Epoch: 48 [3840/7664 (50%)]\tLoss: 0.286762\n",
      "Train Epoch: 48 [4480/7664 (58%)]\tLoss: 0.147869\n",
      "Train Epoch: 48 [5120/7664 (67%)]\tLoss: 0.269981\n",
      "Train Epoch: 48 [5760/7664 (75%)]\tLoss: 0.153940\n",
      "Train Epoch: 48 [6400/7664 (83%)]\tLoss: 0.219919\n",
      "Train Epoch: 48 [7040/7664 (92%)]\tLoss: 0.402272\n",
      "\n",
      "Test set: Average loss: 0.2279, Accuracy: 2148/2396 (90%)\n",
      "\n",
      "Train Epoch: 49 [0/7664 (0%)]\tLoss: 0.141727\n",
      "Train Epoch: 49 [640/7664 (8%)]\tLoss: 0.303502\n",
      "Train Epoch: 49 [1280/7664 (17%)]\tLoss: 0.229713\n",
      "Train Epoch: 49 [1920/7664 (25%)]\tLoss: 0.140170\n",
      "Train Epoch: 49 [2560/7664 (33%)]\tLoss: 0.179520\n",
      "Train Epoch: 49 [3200/7664 (42%)]\tLoss: 0.267062\n",
      "Train Epoch: 49 [3840/7664 (50%)]\tLoss: 0.282291\n",
      "Train Epoch: 49 [4480/7664 (58%)]\tLoss: 0.145810\n",
      "Train Epoch: 49 [5120/7664 (67%)]\tLoss: 0.269167\n",
      "Train Epoch: 49 [5760/7664 (75%)]\tLoss: 0.151372\n",
      "Train Epoch: 49 [6400/7664 (83%)]\tLoss: 0.217727\n",
      "Train Epoch: 49 [7040/7664 (92%)]\tLoss: 0.394382\n",
      "\n",
      "Test set: Average loss: 0.2262, Accuracy: 2149/2396 (90%)\n",
      "\n",
      "Train Epoch: 50 [0/7664 (0%)]\tLoss: 0.139962\n",
      "Train Epoch: 50 [640/7664 (8%)]\tLoss: 0.300634\n",
      "Train Epoch: 50 [1280/7664 (17%)]\tLoss: 0.228996\n",
      "Train Epoch: 50 [1920/7664 (25%)]\tLoss: 0.135022\n",
      "Train Epoch: 50 [2560/7664 (33%)]\tLoss: 0.175704\n",
      "Train Epoch: 50 [3200/7664 (42%)]\tLoss: 0.261558\n",
      "Train Epoch: 50 [3840/7664 (50%)]\tLoss: 0.280349\n",
      "Train Epoch: 50 [4480/7664 (58%)]\tLoss: 0.144036\n",
      "Train Epoch: 50 [5120/7664 (67%)]\tLoss: 0.260617\n",
      "Train Epoch: 50 [5760/7664 (75%)]\tLoss: 0.148745\n",
      "Train Epoch: 50 [6400/7664 (83%)]\tLoss: 0.215382\n",
      "Train Epoch: 50 [7040/7664 (92%)]\tLoss: 0.394891\n",
      "\n",
      "Test set: Average loss: 0.2244, Accuracy: 2157/2396 (90%)\n",
      "\n",
      "saving model to  data/defender/fmnist/exp_model_data/for_target/9/model/exp_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Setup train and test loader\n",
    "\n",
    "train_loader = D.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "test_loader = D.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "model_dir = directory + '/model'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "if (SAVE_MODEL):\n",
    "    print('saving model to ', model_dir+\"/exp_model.pt\")\n",
    "    torch.save(model.state_dict(),model_dir+\"/exp_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
