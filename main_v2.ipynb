{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To see how to train, ref the below links:\n",
    "https://github.com/pytorch/examples/tree/master/mnist\n",
    "and\n",
    "https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "\"\"\"\n",
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# MNIST Test dataset and dataloader declaration\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data/', train=False, download=True, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "                   batch_size=1, shuffle=True)\n",
    "\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the network\n",
    "model = Net().to(device)\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import operator as op\n",
    "import functools as ft\n",
    "\n",
    "\n",
    "'''reduce_* helper functions reduce tensors on all dimensions but the first.\n",
    "They are intended to be used on batched tensors where dim 0 is the batch dim.\n",
    "'''\n",
    "\n",
    "\n",
    "def reduce_sum(x, keepdim=True):\n",
    "    # silly PyTorch, when will you get proper reducing sums/means?\n",
    "    for a in reversed(range(1, x.dim())):\n",
    "        x = x.sum(a, keepdim=keepdim)\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduce_mean(x, keepdim=True):\n",
    "    numel = ft.reduce(op.mul, x.size()[1:])\n",
    "    x = reduce_sum(x, keepdim=keepdim)\n",
    "    return x / numel\n",
    "\n",
    "\n",
    "def reduce_min(x, keepdim=True):\n",
    "    for a in reversed(range(1, x.dim())):\n",
    "        x = x.min(a, keepdim=keepdim)[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduce_max(x, keepdim=True):\n",
    "    for a in reversed(range(1, x.dim())):\n",
    "        x = x.max(a, keepdim=keepdim)[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def torch_arctanh(x, eps=1e-6):\n",
    "    x *= (1. - eps)\n",
    "    return (torch.log((1 + x) / (1 - x))) * 0.5\n",
    "\n",
    "\n",
    "def l2r_dist(x, y, keepdim=True, eps=1e-8):\n",
    "    d = (x - y)**2\n",
    "    d = reduce_sum(d, keepdim=keepdim)\n",
    "    d += eps  # to prevent infinite gradient at 0\n",
    "    return d.sqrt()\n",
    "\n",
    "\n",
    "def l2_dist(x, y, keepdim=True):\n",
    "    d = (x - y)**2\n",
    "    return reduce_sum(d, keepdim=keepdim)\n",
    "\n",
    "\n",
    "def l1_dist(x, y, keepdim=True):\n",
    "    d = torch.abs(x - y)\n",
    "    return reduce_sum(d, keepdim=keepdim)\n",
    "\n",
    "\n",
    "def l2_norm(x, keepdim=True):\n",
    "    norm = reduce_sum(x*x, keepdim=keepdim)\n",
    "    return norm.sqrt()\n",
    "\n",
    "\n",
    "def l1_norm(x, keepdim=True):\n",
    "    return reduce_sum(x.abs(), keepdim=keepdim)\n",
    "\n",
    "\n",
    "def rescale(x, x_min=-1., x_max=1.):\n",
    "    return x * (x_max - x_min) + x_min\n",
    "\n",
    "\n",
    "def tanh_rescale(x, x_min=-1., x_max=1.):\n",
    "    return (torch.tanh(x) + 1) * 0.5 * (x_max - x_min) + x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"PyTorch Carlini and Wagner L2 attack algorithm.\n",
    "\n",
    "Based on paper by Carlini & Wagner, https://arxiv.org/abs/1608.04644 and a reference implementation at\n",
    "https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks_tf.py\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "#from .helpers import *\n",
    "\n",
    "\n",
    "class AttackCarliniWagnerL2:\n",
    "\n",
    "    def __init__(self, targeted=True, search_steps=None, max_steps=None, cuda=True, debug=False):\n",
    "        self.debug = debug\n",
    "        self.targeted = targeted\n",
    "        #self.num_classes = 1000\n",
    "        self.num_classes = 10\n",
    "        self.confidence = 0  # FIXME need to find a good value for this, 0 value used in paper not doing much...\n",
    "        self.initial_const = 0.1  # bumped up from default of .01 in reference code\n",
    "        self.binary_search_steps = search_steps or 5\n",
    "        self.repeat = self.binary_search_steps >= 10\n",
    "        self.max_steps = max_steps or 1000\n",
    "        self.abort_early = True\n",
    "        self.clip_min = -1.\n",
    "        self.clip_max = 1.\n",
    "        self.cuda = cuda\n",
    "        self.clamp_fn = 'tanh'  # set to something else perform a simple clamp instead of tanh\n",
    "        self.init_rand = False  # an experiment, does a random starting point help?\n",
    "\n",
    "    def _compare(self, output, target):\n",
    "        if not isinstance(output, (float, int, np.int64)):\n",
    "            output = np.copy(output)\n",
    "            if self.targeted:\n",
    "                output[target] -= self.confidence\n",
    "            else:\n",
    "                output[target] += self.confidence\n",
    "            output = np.argmax(output)\n",
    "        if self.targeted:\n",
    "            return output == target\n",
    "        else:\n",
    "            return output != target\n",
    "\n",
    "    def _loss(self, output, target, dist, scale_const):\n",
    "        # compute the probability of the label class versus the maximum other\n",
    "        \n",
    "        # for the targeted attack, real will contain the current logit values for the targeted class\n",
    "        # This basically tell us what is the current probability of the image being classified as the target class\n",
    "        # multiplying by one hot encoded target ensures that other (index != target) logit values become 0\n",
    "        # sum(1) simply gives us the logit value of the target class\n",
    "        real = (target * output).sum(1)\n",
    "        \n",
    "        # indices other than target class will have their logit values, target index will have -10000\n",
    "        # takes the maximum value when we suppress the logit of the targeted class\n",
    "        # this will give the logit of the most likely other class\n",
    "        # in the first run, this would most likely be the prob of the true class\n",
    "        other = ((1. - target) * output - target * 10000.).max(1)[0]\n",
    "        \n",
    "        print('output: ', output)\n",
    "        print('real: ', real)\n",
    "        print('other: ', other)\n",
    "        \n",
    "        print('dist shape: ', dist.shape)\n",
    "        print('dist: ', dist)\n",
    "        \n",
    "        if self.targeted:\n",
    "            # if targeted, optimize for making the other class most likely\n",
    "            loss1 = torch.clamp(other - real + self.confidence, min=0.)  # equiv to max(..., 0.)\n",
    "        else:\n",
    "            # if non-targeted, optimize for making this class least likely.\n",
    "            loss1 = torch.clamp(real - other + self.confidence, min=0.)  # equiv to max(..., 0.)\n",
    "        \n",
    "        loss1 = torch.sum(scale_const * loss1)\n",
    "        loss2 = dist.sum()\n",
    "        \n",
    "        print('loss2 which is dist.sum: ', loss2)\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        print('loss: ', loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _optimize(self, optimizer, model, input_var, modifier_var, target_var, scale_const_var, input_orig=None):\n",
    "        # apply modifier and clamp resulting image to keep bounded from clip_min to clip_max\n",
    "        if self.clamp_fn == 'tanh':\n",
    "            input_adv = tanh_rescale(modifier_var + input_var, self.clip_min, self.clip_max)\n",
    "        else:\n",
    "            input_adv = torch.clamp(modifier_var + input_var, self.clip_min, self.clip_max)\n",
    "\n",
    "        output = model(input_adv)\n",
    "\n",
    "        # distance to the original input data\n",
    "        if input_orig is None:\n",
    "            dist = l2_dist(input_adv, input_var, keepdim=False)\n",
    "        else:\n",
    "            dist = l2_dist(input_adv, input_orig, keepdim=False)\n",
    "            \n",
    "            \n",
    "\n",
    "        loss = self._loss(output, target_var, dist, scale_const_var)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #loss_np = loss.data[0] #throws error\n",
    "        loss_np = loss.data\n",
    "        dist_np = dist.data.cpu().numpy()\n",
    "        output_np = output.data.cpu().numpy()\n",
    "        input_adv_np = input_adv.data.permute(0, 2, 3, 1).cpu().numpy()  # back to BHWC for numpy consumption\n",
    "        return loss_np, dist_np, output_np, input_adv_np\n",
    "\n",
    "    def run(self, model, input, target, batch_idx=0):\n",
    "        batch_size = input.size(0)\n",
    "        print('batch size: ', batch_size)\n",
    "        # set the lower and upper bounds accordingly\n",
    "        lower_bound = np.zeros(batch_size)\n",
    "        scale_const = np.ones(batch_size) * self.initial_const\n",
    "        upper_bound = np.ones(batch_size) * 1e10\n",
    "\n",
    "        # python/numpy placeholders for the overall best l2, label score, and adversarial image\n",
    "        o_best_l2 = [1e10] * batch_size\n",
    "        o_best_score = [-1] * batch_size\n",
    "        o_best_attack = input.permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "        # setup input (image) variable, clamp/scale as necessary\n",
    "        if self.clamp_fn == 'tanh':\n",
    "            # convert to tanh-space, input already int -1 to 1 range, does it make sense to do\n",
    "            # this as per the reference implementation or can we skip the arctanh?\n",
    "            input_var = autograd.Variable(torch_arctanh(input), requires_grad=False)\n",
    "            input_orig = tanh_rescale(input_var, self.clip_min, self.clip_max)\n",
    "        else:\n",
    "            input_var = autograd.Variable(input, requires_grad=False)\n",
    "            input_orig = None\n",
    "\n",
    "        # setup the target variable, we need it to be in one-hot form for the loss function\n",
    "        target_onehot = torch.zeros(target.size() + (self.num_classes,))\n",
    "        if self.cuda:\n",
    "            target_onehot = target_onehot.cuda()\n",
    "        target_onehot.scatter_(1, target.unsqueeze(1), 1.)\n",
    "        \n",
    "        #target_onehot will have a 1 at the index of the targeted class (in the case of targeted attack)\n",
    "        print('target_onehot: ', target_onehot)\n",
    "        \n",
    "        target_var = autograd.Variable(target_onehot, requires_grad=False)\n",
    "\n",
    "        # setup the modifier variable, this is the variable we are optimizing over\n",
    "        modifier = torch.zeros(input_var.size()).float()\n",
    "        if self.init_rand:\n",
    "            # Experiment with a non-zero starting point...\n",
    "            modifier = torch.normal(means=modifier, std=0.001)\n",
    "        if self.cuda:\n",
    "            modifier = modifier.cuda()\n",
    "        modifier_var = autograd.Variable(modifier, requires_grad=True)\n",
    "\n",
    "        optimizer = optim.Adam([modifier_var], lr=0.0005)\n",
    "\n",
    "        for search_step in range(self.binary_search_steps):\n",
    "            print('Batch: {0:>3}, search step: {1}'.format(batch_idx, search_step))\n",
    "            if self.debug:\n",
    "                print('Const:')\n",
    "                for i, x in enumerate(scale_const):\n",
    "                    print(i, x)\n",
    "            best_l2 = [1e10] * batch_size\n",
    "            best_score = [-1] * batch_size\n",
    "\n",
    "            # The last iteration (if we run many steps) repeat the search once.\n",
    "            if self.repeat and search_step == self.binary_search_steps - 1:\n",
    "                scale_const = upper_bound\n",
    "\n",
    "            scale_const_tensor = torch.from_numpy(scale_const).float()\n",
    "            if self.cuda:\n",
    "                scale_const_tensor = scale_const_tensor.cuda()\n",
    "            scale_const_var = autograd.Variable(scale_const_tensor, requires_grad=False)\n",
    "\n",
    "            prev_loss = 1e6\n",
    "            for step in range(self.max_steps):\n",
    "                # perform the attack\n",
    "                loss, dist, output, adv_img = self._optimize(\n",
    "                    optimizer,\n",
    "                    model,\n",
    "                    input_var,\n",
    "                    modifier_var,\n",
    "                    target_var,\n",
    "                    scale_const_var,\n",
    "                    input_orig)\n",
    "\n",
    "                if step % 100 == 0 or step == self.max_steps - 1:\n",
    "                    print('Step: {0:>4}, loss: {1:6.4f}, dist: {2:8.5f}, modifier mean: {3:.5e}'.format(\n",
    "                        step, loss, dist.mean(), modifier_var.data.mean()))\n",
    "\n",
    "                if self.abort_early and step % (self.max_steps // 10) == 0:\n",
    "                    if loss > prev_loss * .9999:\n",
    "                        print('Aborting early...')\n",
    "                        break\n",
    "                    prev_loss = loss\n",
    "\n",
    "                # update best result found\n",
    "                for i in range(batch_size):\n",
    "                    target_label = target[i]\n",
    "                    output_logits = output[i]\n",
    "                    output_label = np.argmax(output_logits)\n",
    "                    di = dist[i]\n",
    "                    if self.debug:\n",
    "                        if step % 100 == 0:\n",
    "                            print('{0:>2} dist: {1:.5f}, output: {2:>3}, {3:5.3}, target {4:>3}'.format(\n",
    "                                i, di, output_label, output_logits[output_label], target_label))\n",
    "                    if di < best_l2[i] and self._compare(output_logits, target_label):\n",
    "                        if self.debug:\n",
    "                            print('{0:>2} best step,  prev dist: {1:.5f}, new dist: {2:.5f}'.format(\n",
    "                                  i, best_l2[i], di))\n",
    "                        best_l2[i] = di\n",
    "                        best_score[i] = output_label\n",
    "                    if di < o_best_l2[i] and self._compare(output_logits, target_label):\n",
    "                        if self.debug:\n",
    "                            print('{0:>2} best total, prev dist: {1:.5f}, new dist: {2:.5f}'.format(\n",
    "                                  i, o_best_l2[i], di))\n",
    "                        o_best_l2[i] = di\n",
    "                        o_best_score[i] = output_label\n",
    "                        o_best_attack[i] = adv_img[i]\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                # end inner step loop\n",
    "\n",
    "            # adjust the constants\n",
    "            batch_failure = 0\n",
    "            batch_success = 0\n",
    "            for i in range(batch_size):\n",
    "                if self._compare(best_score[i], target[i]) and best_score[i] != -1:\n",
    "                    # successful, do binary search and divide const by two\n",
    "                    upper_bound[i] = min(upper_bound[i], scale_const[i])\n",
    "                    if upper_bound[i] < 1e9:\n",
    "                        scale_const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
    "                    if self.debug:\n",
    "                        print('{0:>2} successful attack, lowering const to {1:.3f}'.format(\n",
    "                            i, scale_const[i]))\n",
    "                else:\n",
    "                    # failure, multiply by 10 if no solution found\n",
    "                    # or do binary search with the known upper bound\n",
    "                    lower_bound[i] = max(lower_bound[i], scale_const[i])\n",
    "                    if upper_bound[i] < 1e9:\n",
    "                        scale_const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
    "                    else:\n",
    "                        scale_const[i] *= 10\n",
    "                    if self.debug:\n",
    "                        print('{0:>2} failed attack, raising const to {1:.3f}'.format(\n",
    "                            i, scale_const[i]))\n",
    "                if self._compare(o_best_score[i], target[i]) and o_best_score[i] != -1:\n",
    "                    batch_success += 1\n",
    "                else:\n",
    "                    batch_failure += 1\n",
    "\n",
    "            print('Num failures: {0:2d}, num successes: {1:2d}\\n'.format(batch_failure, batch_success))\n",
    "            sys.stdout.flush()\n",
    "            # end outer search loop\n",
    "\n",
    "        return o_best_attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGETED = True\n",
    "MAX_STEPS = 1000\n",
    "SEARCH_STEPS = 6\n",
    "NO_CUDA = False\n",
    "DEBUG = False\n",
    "\n",
    "attack = AttackCarliniWagnerL2(\n",
    "        targeted=TARGETED,\n",
    "        max_steps=MAX_STEPS,\n",
    "        search_steps=SEARCH_STEPS,\n",
    "        cuda=not NO_CUDA,\n",
    "        debug=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for batch_idx, (input, target) in enumerate(loader):\n",
    "    \n",
    "#     input = input.cuda()\n",
    "#     target = target.cuda()\n",
    "\n",
    "#     input_adv = attack.run(model, input, target, batch_idx)\n",
    "\n",
    "#     start_index = args.batch_size * batch_idx\n",
    "#     indices = list(range(start_index, start_index + input.size(0)))\n",
    "#     for filename, o in zip(dataset.filenames(indices, basename=True), input_adv):\n",
    "#         output_file = os.path.join(args.output_dir, filename)\n",
    "#         imsave(output_file, (o + 1.0) * 0.5, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = test_loader\n",
    "\n",
    "iterations = 0\n",
    "thresh_on_iterations = 1\n",
    "\n",
    "success_record = []\n",
    "\n",
    "for batch_idx, (input_tensor, input_label) in enumerate(loader):\n",
    "    print('\\n\\n-------iteration: {}----------'.format(iterations))\n",
    "    \n",
    "    # clean image\n",
    "    input_tensor = input_tensor.cuda()\n",
    "    \n",
    "    # original label for the clean image\n",
    "    input_label = input_label.cuda()   \n",
    "    \n",
    "    # if the attack is targeted, we will target the next class modulo number of classes\n",
    "    if TARGETED == True:\n",
    "        target = (input_label+1)%10\n",
    "    # else the target is kept as the original label as per attack design\n",
    "    else:\n",
    "        target = input_label\n",
    "    \n",
    "    # result obtained is a numpy array\n",
    "    adversarial_img = attack.run(model, input_tensor, target, batch_idx)\n",
    "    \n",
    "    # reshape\n",
    "    adversarial_img = np.transpose(adversarial_img, (0,3,1,2))\n",
    "    \n",
    "    # conver to torch tensor\n",
    "    adversarial_tensor = torch.from_numpy(adversarial_img).cuda()\n",
    "    \n",
    "    # obtain the prediction by the model\n",
    "    pred_adv = model(adversarial_tensor)\n",
    "    \n",
    "    clean_label = input_label.item()\n",
    "    pred_adv_label = torch.max(pred_adv, 1)[1].item()\n",
    "    \n",
    "    print('Original label of the clean image is: {} and predicted label of the adversarial image is {}'\\\n",
    "          .format(clean_label,pred_adv_label))\n",
    "    \n",
    "    result = 0\n",
    "    if TARGETED:\n",
    "        if pred_adv_label == target.item():\n",
    "            result = 1\n",
    "    else:\n",
    "        if pred_adv_label != clean_label:\n",
    "            result = 1\n",
    "    \n",
    "    success_record.append(result)\n",
    "    \n",
    "    iterations += 1\n",
    "    if iterations == thresh_on_iterations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clean = input_tensor.cpu().numpy()\n",
    "plt.imshow(img_clean[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adversarial_img[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_onehot_ar = np.array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "target_onehot = torch.from_numpy(target_onehot_ar)\n",
    "target_onehot = target_onehot.cuda()\n",
    "\n",
    "output_ar = np.array([[-5.3372, -5.6212, -4.7658, -3.9166, -2.1613, -3.9361, -6.2410, -2.7965,-2.5990, -0.3694]])\n",
    "output = torch.from_numpy(output_ar)\n",
    "output = output.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target_onehot * output).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = (target_onehot * output).sum(1)\n",
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = ((1. - target_onehot) * output - target_onehot * 10000.)\n",
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = (other).max(1)[0]\n",
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other - real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clamp(other - real, min=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_onehot:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
    "# Batch:   0, search step: 0\n",
    "# output:  tensor([[-5.3372, -5.6212, -4.7658, -3.9166, -2.1613, -3.9361, -6.2410, -2.7965,\n",
    "#          -2.5990, -0.3694]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
    "real:  tensor([-5.3372], device='cuda:0', grad_fn=<SumBackward1>)\n",
    "other:  tensor([-0.3694], device='cuda:0', grad_fn=<MaxBackward0>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real = (target * output).sum(1)\n",
    "other = ((1. - target) * output - target * 10000.).max(1)[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
