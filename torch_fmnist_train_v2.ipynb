{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pytorch Model for Fashion MNIST using features and classifier methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data as D\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, features, num_classes, init_weights=True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4*4*50, 500),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(500, num_classes)\n",
    "        )\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        # x are the logits values\n",
    "        return x \n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            output = F.log_softmax(output, dim=1)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\"\"\"\n",
    "\n",
    "def make_layers(cfg, in_channels, kernel_size, stride, padding, batch_norm=False):\n",
    "    layers = []\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=kernel_size, padding=padding)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Refer VGG19_bn configurationh here: \n",
    "https://github.com/pytorch/vision/blob/76702a03d6cc2e4f431bfd1914d5e301c07bd489/torchvision/models/vgg.py#L63\n",
    "\"\"\"\n",
    "cfgs = {\n",
    "    #'E': [64, 64, 'M',128, 128, 'M',256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M',512, 512, 512, 512, 'M'],\n",
    "    'E': [20, 'M', 50, 'M']\n",
    "}\n",
    "\n",
    "model_layers = make_layers(cfgs['E'],in_channels=1, kernel_size=5, stride=1, padding=0, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomDS(D.Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, train=True):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            data_path = os.path.join(path,'x_train.npy')\n",
    "            targets_path = os.path.join(path,'y_train.npy')\n",
    "        else:\n",
    "            data_path = os.path.join(path,'x_test.npy')\n",
    "            targets_path = os.path.join(path,'y_test.npy')\n",
    "\n",
    "        self.path = data_path\n",
    "        self.data = np.load(data_path)\n",
    "        self.targets = np.load(targets_path)\n",
    "        #self.transform = transforms.ToTensor()\n",
    "        self.transform = transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "        self.len = np.shape(self.data)[0]\n",
    "        \n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        data = self.data[index]\n",
    "        image = Image.fromarray(data)\n",
    "        \n",
    "        target = int(self.targets[index])\n",
    "        \n",
    "        #data = (data * 255).astype(np.uint8)\n",
    "        #data = data.reshape(28,28)\n",
    "        #image = Image.fromarray((data * 255).astype(np.uint8))\n",
    "        #image = Image.fromarray(data.astype(np.uint8))\n",
    "        \n",
    "        return self.transform(image), target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (60000, 28, 28)\n",
      "y_train shape : (60000,)\n",
      "x_test shape : (10000, 28, 28)\n",
      "y_test shape : (10000,)\n",
      "x_train shape : (60000, 28, 28)\n",
      "y_train shape : (60000,)\n",
      "x_test shape : (10000, 28, 28)\n",
      "y_test shape : (10000,)\n",
      "row, col, channels : (28, 28)\n",
      "num of classes: 60000\n"
     ]
    }
   ],
   "source": [
    "directory = './data/fmnist'\n",
    "IS_DATA_READY = False\n",
    "\n",
    "if not IS_DATA_READY:\n",
    "\n",
    "    (x_train, y_train) ,(x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "    print('x_train shape : {}'.format(x_train.shape))\n",
    "    print('y_train shape : {}'.format(y_train.shape))\n",
    "    print('x_test shape : {}'.format(x_test.shape))\n",
    "    print('y_test shape : {}'.format(y_test.shape))\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Normalize\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    nb_classes = y_train.shape[0]\n",
    "\n",
    "    #debug- Play around with MNIST here\n",
    "    print('x_train shape : {}'.format(x_train.shape))\n",
    "    print('y_train shape : {}'.format(y_train.shape))\n",
    "    print('x_test shape : {}'.format(x_test.shape))\n",
    "    print('y_test shape : {}'.format(y_test.shape))\n",
    "\n",
    "    print('row, col, channels : {}'.format(x_train.shape[1:4]))\n",
    "    print('num of classes: {}'.format(nb_classes))\n",
    "\n",
    "    np.save(directory + '/x_train.npy', x_train)\n",
    "    np.save(directory + '/y_train.npy', y_train)\n",
    "    np.save(directory + '/x_test.npy', x_test)\n",
    "    np.save(directory + '/y_test.npy', y_test)\n",
    "\n",
    "else:\n",
    "    x_train = np.load(directory + '/x_train.npy')\n",
    "    y_train = np.load(directory + '/y_train.npy')\n",
    "    x_test = np.load(directory + '/x_test.npy')\n",
    "    y_test = np.load(directory + '/y_test.npy')\n",
    "    print('x_train shape : {}'.format(x_train.shape))\n",
    "    print('y_train shape : {}'.format(y_train.shape))\n",
    "    print('x_test shape : {}'.format(x_test.shape))\n",
    "    print('y_test shape : {}'.format(y_test.shape))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Simple dataset. Only save path to image and load it and transform to tensor when call __getitem__.\n",
    "filepath = './data/fmnist/'\n",
    "train_set = CustomDS(filepath, train=True)\n",
    "test_set = CustomDS(filepath, train=False)\n",
    "\n",
    "# total images in set\n",
    "print(train_set.len)\n",
    "print(test_set.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main method\n",
    "## Training settings\n",
    "# input batch size for training (default: 64)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# input batch size for testing (default: 1000)\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "# number of epochs to train\n",
    "EPOCHS = 10\n",
    "\n",
    "#learning rate (default: 0.01)\n",
    "LR = 0.01\n",
    "\n",
    "#SGD momentum (default: 0.5)\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "# how many batches to wait before logging training status\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "SAVE_MODEL = True\n",
    "SEED = 1\n",
    "NO_CUDA = False\n",
    "USE_CUDA = not NO_CUDA and torch.cuda.is_available()\n",
    "\n",
    "NUM_CLASSES=10\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net(model_layers, num_classes=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=500, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301888\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.301827\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.301926\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.299537\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.298868\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.297620\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.294904\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.296936\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.294505\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.296245\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.294113\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.285389\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.286449\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.281996\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.281533\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.274305\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.279547\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.266178\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.255972\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.248618\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.231387\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.230573\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.194827\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.155803\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.129120\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.078542\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.934870\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.829588\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.660193\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.570819\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.421323\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.391002\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.102620\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.064071\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.232495\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.084972\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.140855\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.096543\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.147424\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.996368\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.975396\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.046757\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.015201\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.052606\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.014676\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.064680\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.194660\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.930404\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.106543\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.854402\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.003799\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.858922\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.872994\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.018868\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.946935\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.837704\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.874011\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.944725\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.840415\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.926654\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.896147\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.804228\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.940895\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.721464\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.891752\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.967496\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.943307\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.751843\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.808199\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.005503\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.855236\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.820313\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.881042\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.862488\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.847190\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.639953\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.859388\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.824798\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.781417\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.977826\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.778546\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.753545\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.806418\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.887066\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.699301\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.874160\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.694992\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.626666\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.822634\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.882310\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.821832\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.648586\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.902200\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.914231\n",
      "\n",
      "Test set: Average loss: 0.7792, Accuracy: 7157/10000 (72%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.751998\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.503653\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.718502\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.672173\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.800084\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.829966\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.053535\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.697981\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.777682\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.603346\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.743106\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.637738\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.609493\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.823135\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.866124\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.919083\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.817169\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.735796\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.974715\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.849327\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.500393\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.807194\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.656370\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.577431\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.750484\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.828484\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.649817\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.754099\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.645868\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.788550\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.769848\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.682972\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.585351\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.535845\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.819458\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.476153\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.774350\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.715042\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.716701\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.682853\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.656771\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.777882\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.728809\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.676648\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.699355\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.757831\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.942572\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.771568\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.773982\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.532342\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.753552\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.513012\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.525193\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.687824\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.694944\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.540372\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.607070\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.659067\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.581733\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.645071\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.648464\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.615026\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.593023\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.535251\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.699234\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.719107\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.639846\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.569699\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.491421\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.646431\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.605116\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.641272\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.768771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.598896\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.621870\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.545076\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.621133\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.710073\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.682010\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.789783\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.615374\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.670855\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.767937\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.763743\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.555218\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.720700\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.459997\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.516755\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.705824\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.725887\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.645141\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.453565\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.739085\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.643124\n",
      "\n",
      "Test set: Average loss: 0.6048, Accuracy: 7796/10000 (78%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.534433\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.417629\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.612877\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.596627\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.610664\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.696575\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.885117\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.529322\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.572904\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.461772\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.578004\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.513943\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.465597\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.717488\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.723208\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.727235\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.562487\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.594016\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.818990\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.683266\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.378398\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.624830\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.545919\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.481026\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.512130\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.754966\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.517756\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.642208\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.570129\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.655449\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.627682\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.580497\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.468927\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.400534\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.706311\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.340871\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.607606\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.531563\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.586843\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.570187\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.617791\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.705433\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.715003\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.541792\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.571427\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.630345\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.843128\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.676267\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.608331\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.386575\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.644750\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.391963\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.393146\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.639513\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.541597\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.445931\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.478016\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.541768\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.446382\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.501709\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.534577\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.457410\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.458496\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.485032\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.652645\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.651489\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.525866\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.502926\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.379849\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.500433\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.548559\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.504713\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.690453\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.525075\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.542290\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.494505\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.527708\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.638492\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.639382\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.606138\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.562591\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.575825\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.649247\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.715929\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.455275\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.635464\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.359630\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.484919\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.654786\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.578634\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.516584\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.370894\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.587539\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.536740\n",
      "\n",
      "Test set: Average loss: 0.5224, Accuracy: 8159/10000 (82%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.430164\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.422487\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.541456\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.561336\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.505825\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.619895\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.785010\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.454613\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.494176\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.398327\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.517040\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.426139\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.394773\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.600004\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.631598\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.648708\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.455729\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.494819\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.708361\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.576819\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.322337\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.522827\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.464990\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.419611\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.381152\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.676239\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.488552\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.561906\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.551894\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.575608\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.542846\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.550422\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.405206\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.343768\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.612905\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.275084\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.553287\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.448262\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.521208\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.471842\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.588902\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.615673\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.678934\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.488222\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.470432\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.543050\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.771900\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.613235\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.504174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.322535\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.573666\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.312201\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.305687\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.632319\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.491366\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.405362\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.423619\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.489569\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.357565\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.415201\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.462880\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.385194\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.397520\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.451289\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.585726\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.579395\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.481007\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.457284\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.349864\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.424868\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.530607\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.431052\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.636344\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.482462\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.462341\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.457324\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.478219\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.558224\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.620164\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.464098\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.541053\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.514905\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.567484\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.695121\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.389612\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.550402\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.309878\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.453156\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.592580\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.511943\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.442546\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.330706\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.483041\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.482991\n",
      "\n",
      "Test set: Average loss: 0.4721, Accuracy: 8350/10000 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.376343\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.417953\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.472843\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.502428\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.442473\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.561194\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.718633\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.416882\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.464298\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.366243\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.461925\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.378728\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.352035\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.492549\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.576869\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.602236\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.432479\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.427928\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.609233\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.508506\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.274717\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.475513\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.408129\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.378599\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.335276\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.634014\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.493193\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.497003\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.541627\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.527960\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.486019\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.528888\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.360392\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.313568\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.532260\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.239443\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.535175\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.400636\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.495374\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.416490\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.524987\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.554668\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.622842\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.462996\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.399965\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.477510\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.685285\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.557376\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.445263\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.297154\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.532343\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.262530\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.264364\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.627179\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.459980\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.386918\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.414636\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.476186\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.309272\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.349184\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.421781\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.341071\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.349168\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.438426\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.531851\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.503100\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.441855\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.401066\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.333546\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.392718\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.526930\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.372420\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.588092\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.436162\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.400593\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.428394\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.445277\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.502488\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.607249\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.370442\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.521170\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.464262\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.503412\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.658162\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.342624\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.480236\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.277355\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.419262\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.541012\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.479114\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.407806\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.297337\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.417344\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.441499\n",
      "\n",
      "Test set: Average loss: 0.4346, Accuracy: 8464/10000 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.339083\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.401962\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.423492\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.443236\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.406408\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.484863\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.663547\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.395091\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.448807\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.334285\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.419401\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.342215\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.320550\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.419151\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.526111\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.573362\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.428872\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.374479\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.524203\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.463175\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.235369\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.429680\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.358232\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.350373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.312874\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.609504\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.499637\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.441063\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.516226\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.465703\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.441579\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.499623\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.329968\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.301503\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.475752\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.221940\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.506844\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.381009\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.470067\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.372686\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.468560\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.526456\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.546109\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.446932\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.345802\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.419061\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.621566\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.518641\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.414245\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.277489\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.497237\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.230911\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.235176\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.624528\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.451618\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.383696\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.417191\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.470331\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.265494\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.301244\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.395748\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.303031\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.319211\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.422005\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.499856\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.440488\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.406777\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.353329\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.314804\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.365582\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.524207\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.334484\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.560567\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.396967\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.349926\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.414505\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.427025\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.466333\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.600773\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.309531\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.510804\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.421838\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.452801\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.607126\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.303036\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.419342\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.256566\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.404934\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.501615\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.470636\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.396713\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.279141\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.373438\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.411962\n",
      "\n",
      "Test set: Average loss: 0.4091, Accuracy: 8572/10000 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.304848\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.384177\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.374545\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.399259\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.387271\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.425118\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.613224\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.365851\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.434402\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.307223\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.382539\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.314949\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.307684\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.368867\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.490163\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.566234\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.423694\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.351129\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.466101\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.439668\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.219538\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.401974\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.331292\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.328845\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.299491\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.579451\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.496569\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.408840\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.487035\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.432429\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.413839\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.465906\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.313110\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.286534\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.430352\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.215218\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.489120\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.362110\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.449269\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.338822\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.416538\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.502500\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.481974\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.424231\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.320770\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.368787\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.581554\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.485167\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.393314\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.260919\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.469934\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.221548\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.211070\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.616780\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.449396\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.376731\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.410175\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.464652\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.237335\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.262896\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.380054\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.278651\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.295006\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.405640\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.467159\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.413493\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.385334\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.331880\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.305811\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.345897\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.530497\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.302429\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.545409\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.364258\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.326226\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.396403\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.397621\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.459950\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.599806\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.268723\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.501606\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.393173\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.427855\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.563454\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.275471\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.383351\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.237369\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.381198\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.459754\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.447297\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.394546\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.265887\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.345787\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.398170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3920, Accuracy: 8612/10000 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.279531\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.375819\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.355754\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.365645\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.378652\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.388085\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.595099\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.344046\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.424311\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.282626\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.354069\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.295347\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.288282\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.340398\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.452650\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.569034\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.406378\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.334370\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.430768\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.428813\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.207311\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.377019\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.300780\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.305971\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.294011\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.557263\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.485149\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.387480\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.449246\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.405656\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.392288\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.434740\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.305836\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.272144\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.398420\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.210537\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.477319\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.347507\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.419563\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.317651\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.391864\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.475938\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.446340\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.400463\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.299671\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.334904\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.532539\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.469780\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.381479\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.244577\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.453393\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.211580\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.191485\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.610379\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.437829\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.365428\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.394402\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.461498\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.218045\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.237688\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.372441\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.262903\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.274416\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.377846\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.432758\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.386718\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.376411\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.306411\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.291609\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.328297\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.534620\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.283002\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.522521\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.338126\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.317918\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.383225\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.361583\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.445518\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.594126\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.245689\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.499495\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.365837\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.406027\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.531132\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.256351\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.349085\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.227412\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.366988\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.434025\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.441930\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.395073\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.250903\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.319530\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.388283\n",
      "\n",
      "Test set: Average loss: 0.3790, Accuracy: 8637/10000 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.257838\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.365562\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.348663\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.341156\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.382105\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.360066\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.583144\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.325813\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.412707\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.259975\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.330650\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.275465\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.274646\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.316954\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.429000\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.565753\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.385014\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.329087\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.407882\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.418148\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.199530\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.369085\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.281237\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.295184\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.292660\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.540909\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.474119\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.369919\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.420805\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.382181\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.372017\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.422231\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.310481\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.260924\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.370463\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.197235\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.475654\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.333420\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.388686\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.314138\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.370350\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.450814\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.411753\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.379409\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.284464\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.314046\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.467887\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.463821\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.374938\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.225248\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.434790\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.204449\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.176983\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.603163\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.425535\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.358508\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.373503\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.463837\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.203647\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.206967\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.364252\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.254185\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.266365\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.368503\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.396323\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.368292\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.366136\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.296750\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.283904\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.316302\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.535666\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.260204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.504989\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.326990\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.299590\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.375933\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.341412\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.437182\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.594738\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.227760\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.489636\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.351020\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.391382\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.493707\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.241426\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.325204\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.219194\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.356531\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.409978\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.429063\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.385867\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.243205\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.297762\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.375233\n",
      "\n",
      "Test set: Average loss: 0.3676, Accuracy: 8681/10000 (87%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.237638\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.355347\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.338151\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.320669\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.381936\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.339696\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.573175\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.306719\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.404252\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.243424\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.304740\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.261607\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.267653\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.305104\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.413270\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.544578\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.367342\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.312863\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.379567\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.407700\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.192624\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.345982\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.261298\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.276286\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.300893\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.521071\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.462379\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.358888\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.400936\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.350097\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.355325\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.414411\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.308687\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.257259\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.349275\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.186364\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.467282\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.327177\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.375667\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.303436\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.351144\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.419749\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.387942\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.366954\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.273151\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.295087\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.439500\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.454341\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.357925\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.221178\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.417231\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.200076\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.166004\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.587232\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.415087\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.345469\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.363358\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.461746\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.193203\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.184358\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.355618\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.240482\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.254458\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.351804\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.371440\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.350767\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.361813\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.274690\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.272643\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.300110\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.525892\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.253380\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.490585\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.308389\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.284929\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.380925\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.318058\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.426344\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.597238\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.218501\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.472485\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.343646\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.377713\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.469987\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.232407\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.314837\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.207308\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.343225\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.392469\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.419543\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.380805\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.239025\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.278282\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.360978\n",
      "\n",
      "Test set: Average loss: 0.3595, Accuracy: 8704/10000 (87%)\n",
      "\n",
      "saving model to  ./model/fmnist/v2/fmnist_cnn.pt\n"
     ]
    }
   ],
   "source": [
    "# Setup train and test loader\n",
    "\n",
    "train_loader = D.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "test_loader = D.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "model_dir = './model/fmnist/v2'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "if (SAVE_MODEL):\n",
    "    print('saving model to ', model_dir+\"/fmnist_cnn.pt\")\n",
    "    torch.save(model.state_dict(),model_dir+\"/fmnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = iter(train_loader).next()\n",
    "data.shape\n",
    "#target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
